2024-11-17:14:43:16 [INFO    ] [fp.py:202] {'acc_ratio': 0.1,
 'amp': True,
 'batch_size': 256,
 'client_optimizer': 'sgd',
 'dataset': 'cifar10',
 'dataset_path': 'data//cifar10',
 'defense_save_path': 'record/sig_0_1_ViT/defense/fp',
 'device': 'cuda:0',
 'epochs': 20,
 'frequency_save': 0,
 'img_size': (32, 32, 3),
 'index': None,
 'input_channel': 3,
 'input_height': 32,
 'input_width': 32,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'vit_b_16',
 'non_blocking': True,
 'num_classes': 10,
 'num_workers': 4,
 'once_prune_ratio': 0.01,
 'pin_memory': True,
 'poison_rate': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'ratio': 0.05,
 'result_file': 'sig_0_1_ViT',
 'sgd_momentum': 0.9,
 'target_label': 0,
 'target_type': 'all2one',
 'terminal_info': ['./defense/fp.py',
                   '--result_file',
                   'sig_0_1_ViT',
                   '--yaml_path',
                   './config-vit/defense/fp/cifar10.yaml',
                   '--dataset',
                   'cifar10',
                   '--epochs',
                   '20',
                   '--ratio',
                   '0.05',
                   '--device',
                   'cuda:0',
                   '--model',
                   'vit_b_16'],
 'trigger_type': 'squareTrigger',
 'wd': 0.0005,
 'yaml_path': './config-vit/defense/fp/cifar10.yaml'}
2024-11-17:14:43:16 [DEBUG   ] [fp.py:204] Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
2024-11-17:14:43:16 [DEBUG   ] [fp.py:208] {'git hash': None,
 'last 3 log': 'commit f2ca5f8f4b58e07a407dd65ca217f11673aba63d\n'
               'Author: soheilzi <soheil.zibakhsh@gmail.com>\n'
               'Date:   Tue Nov 12 09:46:15 2024 -0800\n'
               '\n'
               '    added the adverserial test, added the trojan tests with '
               'MG\n'
               '\n'
               'commit afd704e7564791ddc0ae120c7d2e1581bd3a4f80\n'
               'Author: Yaman <yamanjandali@gmail.com>\n'
               'Date:   Fri Nov 8 16:15:34 2024 -0800\n'
               '\n'
               '    removed added files\n'
               '\n'
               'commit 9bc0c704e4be5beff4562e38a15f0b4e070bb433\n'
               'Author: Yaman <yamanjandali@gmail.com>\n'
               'Date:   Tue Nov 5 10:24:03 2024 -0800\n'
               '\n'
               '    updated train_settings_generate.py file',
 'status': 'On branch main\n'
           "Your branch is up to date with 'origin/main'.\n"
           '\n'
           'Changes not staged for commit:\n'
           '  (use "git add <file>..." to update what will be committed)\n'
           '  (use "git restore <file>..." to discard changes in working '
           'directory)\n'
           '\tmodified:   attack/trojannn.py\n'
           '\tmodified:   config/attack/badnet/default.yaml\n'
           '\tmodified:   config/attack/trojannn/vit_b_16.yaml\n'
           '\tmodified:   config/attack/wanet/default.yaml\n'
           '\tmodified:   config/defense/ft-sam/cifar10.yaml\n'
           '\tmodified:   testing_adverserial/adverserial_test.ipynb\n'
           '\n'
           'Untracked files:\n'
           '  (use "git add <file>..." to include in what will be committed)\n'
           '\tattackOut.txt\n'
           '\tconfig-vit/\n'
           '\toutputPane.txt\n'
           '\toutputPaneWaNet.txt\n'
           '\trecord/badnet_0_1_RN18/\n'
           '\trecord/badnet_0_1_ViT/\n'
           '\trecord/blended_0_1_RN18/\n'
           '\trecord/blended_0_1_ViT/\n'
           '\trecord/inputaware_0_1_RN18FR/\n'
           '\trecord/inputaware_0_1_ViT/\n'
           '\trecord/sig_0_1_RN18FR/\n'
           '\trecord/sig_0_1_ViT/\n'
           '\trecord/sig_0_1_ViTOG/\n'
           '\trecord/trojannn_0_1_RN18/\n'
           '\trecord/trojannn_0_1_ViT2/\n'
           '\trecord/wanet_0_1_RN18/\n'
           '\trecord/wanet_0_1_ViT/\n'
           '\tresource/clean_model/\n'
           '\trun_attacks.sh\n'
           '\trun_attacks2.sh\n'
           '\trun_attacksRN18.sh\n'
           '\trun_attacks_ViT.sh\n'
           '\trun_defenses.sh\n'
           '\trun_defensesRN18.sh\n'
           '\ttesting_adverserial/adverserial_test2.ipynb\n'
           '\n'
           'no changes added to commit (use "git add" and/or "git commit -a")'}
2024-11-17:14:43:16 [INFO    ] [save_load_attack.py:210] key match for attack_result, processing...
2024-11-17:14:43:16 [WARNING ] [save_load_attack.py:221] save_path MUST have 'record' in its abspath, and data_path in attack result MUST have 'data' in its path
2024-11-17:14:43:17 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
2024-11-17:14:43:17 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
2024-11-17:14:43:17 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
2024-11-17:14:43:17 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
2024-11-17:14:43:17 [DEBUG   ] [model_trainer_generate.py:59] image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
2024-11-17:14:43:17 [DEBUG   ] [model_trainer_generate.py:122] All vit model use the default pretrain and resize to match the input shape!
2024-11-17:14:43:18 [DEBUG   ] [model_trainer_generate.py:59] image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
2024-11-17:14:43:18 [DEBUG   ] [model_trainer_generate.py:122] All vit model use the default pretrain and resize to match the input shape!
2024-11-17:14:43:20 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
2024-11-17:14:43:20 [INFO    ] [fp.py:247] get ran_idx for subset clean train dataset, (len=2500), ran_idx:[25247, 49673, 27562, 2653, 16968, 33506, 31845, 26537, 19877, 31234, 23465, 38232, 14315, 33075, 9127, 18470, 9158, 49532, 6214, 40525, 16417, 34902, 46214, 39446, 9631, 20325, 6472, 47830, 4832, 44825, 21639, 30942, 36687, 6599, 23186, 28453, 20722, 40035, 41970, 13400, 36210, 31261, 29012, 34167, 17071, 4081, 35959, 920, 6112, 47166, 26137, 46547, 43788, 40977, 74, 40101, 32347, 21832, 15984, 47859, 21312, 46113, 4127, 12521, 37192, 14529, 15637, 9338, 35585, 29358, 5977, 5272, 20975, 33288, 32065, 7147, 19755, 36127, 19076, 46305, 8179, 35877, 21807, 35408, 13317, 39530, 35863, 38510, 18851, 29162, 6005, 39078, 25224, 20777, 37725, 15866, 19027, 12050, 12411, 12237, 2160, 40158, 43034, 17043, 31229, 4527, 5886, 44480, 49650, 8534, 9800, 2532, 5259, 45830, 35428, 44793, 25643, 46221, 34378, 18063, 34196, 15433, 14103, 44530, 38653, 27487, 37990, 18036, 29528, 32286, 43269, 42021, 45889, 23420, 5398, 21254, 40159, 7559, 31879, 38474, 41297, 21972, 12476, 15927, 1062, 47938, 17762, 7676, 46224, 14448, 24383, 11172, 21793, 27926, 4075, 6593, 9591, 45722, 14337, 2964, 37608, 41563, 35009, 39463, 44603, 4849, 1749, 8155, 41615, 12354, 39736, 37745, 7844, 25638, 5998, 24257, 7605, 2384, 39682, 1417, 12752, 12122, 47062, 8119, 31407, 13800, 47654, 4003, 44521, 1493, 35667, 27893, 40671, 6651, 17034, 4587, 14472, 4716, 42396, 19730, 22956, 28578, 11817, 4000, 33006, 30613, 2580, 39091, 6613, 25642, 13064, 17048, 23498, 47946, 30816, 37340, 11103, 45724, 44082, 13330, 3804, 44315, 10368, 10613, 22433, 34699, 16429, 7681, 39111, 28987, 43621, 11456, 865, 30908, 44648, 26863, 37297, 33331, 20410, 42528, 23406, 25470, 43097, 16445, 10054, 36739, 45273, 815, 30012, 48599, 5182, 22014, 48432, 2994, 35672, 18407, 8836, 15737, 49949, 31577, 23083, 39985, 18866, 44132, 23540, 38684, 41533, 40702, 8673, 46898, 20335, 25429, 49052, 27159, 42652, 5290, 99, 38966, 12603, 45782, 21915, 10490, 15690, 14620, 41772, 29368, 24815, 46553, 44156, 37234, 27158, 2067, 26362, 45995, 37189, 27408, 43397, 46465, 3065, 10857, 29186, 4186, 16988, 45974, 10334, 29252, 34575, 31933, 36792, 39582, 49511, 4, 2550, 32412, 21361, 20451, 30598, 3267, 27206, 12320, 35950, 41490, 5470, 47549, 8553, 965, 26333, 44467, 27360, 20720, 222, 13993, 936, 47010, 49463, 154, 44286, 34625, 40112, 6408, 12481, 7792, 39869, 42550, 13009, 19819, 18348, 45124, 11942, 6565, 31169, 25997, 41132, 5331, 1431, 18003, 29686, 7587, 16809, 8743, 42832, 34135, 42649, 42266, 22744, 7543, 10121, 18245, 1217, 2772, 2664, 13483, 44629, 17017, 36592, 20625, 24044, 2752, 49095, 45962, 39819, 42949, 32406, 46685, 42214, 30059, 41952, 28537, 24408, 35253, 11684, 13621, 24613, 38477, 19073, 583, 9073, 9897, 17784, 21850, 22119, 24064, 47087, 6141, 22167, 40667, 2337, 2700, 17669, 10738, 9792, 38237, 18974, 23652, 25873, 35945, 8496, 19228, 7529, 31330, 47875, 15709, 3162, 20177, 11769, 34278, 47753, 4644, 19835, 26422, 21529, 19610, 27179, 7120, 6514, 36754, 31534, 31064, 22090, 22521, 8147, 31397, 7602, 45848, 32619, 27953, 2478, 19785, 21959, 48152, 45030, 10201, 10915, 41074, 36994, 41869, 5696, 4314, 5548, 12978, 49143, 14487, 4007, 25219, 514, 6427, 25808, 36469, 34013, 18993, 29395, 32022, 38331, 46819, 44518, 14237, 27724, 5482, 24138, 14426, 17099, 38353, 10917, 28260, 12579, 23495, 7537, 4184, 46006, 1810, 34459, 29596, 49311, 44362, 13217, 32577, 26080, 16808, 13581, 42008, 2759, 14148, 40856, 6857, 12974, 30042, 24774, 23700, 35808, 9917, 6864, 39075, 31975, 9725, 36956, 26601, 41835, 44559, 27737, 34159, 32466, 44519, 21132, 32665, 32679, 41619, 43913, 13237, 35573, 39961, 636, 22296, 46241, 48957, 20857, 21091, 2324, 34413, 9723, 16835, 39491, 10217, 24838, 38204, 19292, 47063, 46292, 30830, 4348, 5547, 33851, 2583, 14751, 8552, 2662, 19690, 1001, 49735, 29398, 21665, 10530, 9753, 42997, 30194, 24334, 33095, 25049, 34721, 32927, 2203, 37609, 5940, 44470, 33947, 49666, 39330, 5004, 48953, 27942, 49454, 13507, 18983, 35089, 39230, 27383, 31602, 25465, 39808, 38429, 15307, 1342, 43056, 15, 48545, 11925, 19820, 33217, 37372, 16676, 21802, 4300, 32342, 17170, 19844, 26743, 25176, 25144, 4080, 10734, 42007, 8344, 15659, 18814, 47805, 21890, 3639, 2354, 31544, 27385, 9234, 32232, 39450, 47001, 5349, 44141, 45789, 9920, 23119, 26944, 2305, 40093, 30558, 25341, 30073, 3082, 6650, 30860, 1325, 2127, 39210, 40461, 8696, 41285, 21227, 6900, 45880, 35988, 42532, 22719, 12777, 25127, 32133, 7274, 3942, 39984, 45928, 30617, 40260, 41439, 22142, 42629, 44730, 46767, 40765, 19423, 8330, 25404, 19254, 48875, 44630, 7966, 12394, 2502, 25691, 29135, 24351, 49585, 12483, 29849, 23367, 41419, 4937, 2925, 2620, 31861, 16736, 1746, 34082, 43680, 37306, 37473, 14154, 15050, 6126, 41119, 32926, 45777, 34321, 27532, 33233, 20008, 7434, 9547, 27916, 37094, 27659, 5507, 6865, 27239, 4123, 6501, 27208, 10233, 48121, 2012, 29276, 28251, 44985, 27329, 1974, 32546, 21266, 47352, 16553, 5147, 23101, 4609, 7954, 23544, 45336, 1925, 22639, 22798, 11659, 653, 15105, 23973, 4621, 39098, 9390, 13630, 211, 13421, 43189, 44155, 47979, 8073, 49019, 470, 19219, 24191, 45184, 1615, 39639, 15260, 9298, 12254, 29756, 7365, 31240, 22573, 46365, 16922, 8530, 1830, 13639, 23739, 21955, 31022, 19177, 19421, 36254, 41675, 21429, 12061, 38864, 5295, 6722, 34945, 38066, 20169, 10250, 24680, 9628, 8207, 14602, 20702, 33314, 15914, 15509, 49470, 12054, 19074, 24409, 27511, 43463, 3031, 8666, 39400, 1346, 5106, 46017, 4797, 8652, 27540, 19620, 36095, 27312, 48554, 9324, 38736, 27668, 19531, 41744, 23236, 5541, 16256, 29151, 41469, 24199, 41749, 34682, 3791, 24669, 26779, 552, 27343, 47722, 21015, 28920, 13368, 24352, 19222, 5967, 12154, 7118, 18151, 7350, 36580, 39685, 45101, 10084, 46045, 29239, 26134, 12149, 27636, 28292, 11451, 16250, 29717, 22307, 34298, 9343, 23289, 30306, 41387, 41766, 5668, 31672, 49481, 13345, 19315, 120, 45809, 29431, 40549, 30278, 509, 14334, 19566, 7501, 41216, 19736, 35730, 39921, 10238, 27800, 46287, 49240, 30895, 6065, 44445, 32615, 49813, 15228, 35634, 49938, 26562, 18355, 41423, 1416, 7918, 17699, 43810, 2657, 16, 16814, 26111, 34478, 38116, 46528, 25967, 29136, 6686, 48925, 16554, 23188, 18572, 49494, 44076, 12847, 39020, 5587, 2323, 4617, 17202, 20028, 34972, 22275, 7745, 34746, 16321, 10718, 4462, 27186, 18985, 18530, 34067, 8809, 37616, 34279, 41100, 13780, 34824, 6901, 26922, 41588, 35623, 26438, 48590, 18259, 19153, 28990, 24366, 37239, 41209, 9031, 10293, 8080, 45680, 7898, 24997, 26294, 38735, 30667, 9144, 36674, 43794, 19592, 23203, 41426, 30976, 48650, 27204, 14287, 31242, 32037, 45527, 32870, 20856, 32290, 42733, 3946, 29096, 19672, 9359, 48838, 32474, 3434, 40707, 14137, 1674, 23291, 30902, 25622, 662, 34526, 4355, 45016, 5332, 44977, 48624, 43844, 25894, 420, 23676, 2698, 7612, 40689, 245, 17716, 41967, 45854, 19171, 47651, 14856, 9219, 49257, 37542, 18869, 12530, 6911, 28443, 30205, 46946, 25174, 11026, 21672, 27637, 42467, 45054, 28525, 9700, 29313, 46453, 9666, 34351, 20714, 8468, 13688, 12243, 29106, 22883, 25485, 28002, 32240, 25528, 47827, 14428, 12857, 28788, 13386, 38438, 46530, 3263, 25450, 2180, 15337, 41495, 12239, 23829, 3734, 48703, 41816, 44400, 11362, 15274, 40028, 19498, 40141, 5677, 46197, 33562, 49249, 18640, 23138, 26963, 30034, 3535, 41410, 45665, 33824, 43622, 42500, 35860, 48130, 28220, 38073, 29792, 32125, 16695, 46144, 31172, 14117, 22098, 17424, 2767, 2870, 3444, 10673, 22924, 253, 18992, 42901, 467, 9201, 4173, 28032, 44597, 14559, 39887, 25985, 36553, 14481, 29733, 12638, 22249, 39866, 6706, 39738, 5611, 20907, 21163, 35120, 29867, 21308, 16744, 1889, 34209, 2906, 12460, 24163, 5250, 13735, 34374, 22658, 12306, 13213, 16467, 44083, 47777, 48208, 19747, 20462, 33875, 25209, 16688, 31593, 22540, 46693, 15726, 2916, 20041, 36174, 4740, 603, 30207, 32460, 47487, 28717, 3110, 27008, 30180, 28842, 7741, 5610, 5339, 15803, 6470, 10079, 27132, 13989, 28877, 40157, 5055, 27979, 36635, 49468, 25852, 2578, 11821, 16366, 32113, 14421, 8394, 18284, 23075, 20945, 28497, 7031, 36507, 18710, 39982, 35459, 13184, 46600, 19440, 28952, 33687, 39627, 30282, 35138, 41573, 17104, 17861, 15190, 1085, 7781, 40296, 46655, 6481, 11309, 48030, 27175, 16303, 14291, 18648, 48239, 43228, 422, 48622, 35096, 33769, 28067, 3261, 7981, 25211, 42283, 17857, 7749, 48318, 37006, 23521, 15044, 44229, 46959, 46103, 35824, 43293, 18492, 14520, 48488, 4245, 33957, 20153, 44213, 21450, 15309, 24457, 41190, 31474, 18797, 38145, 11231, 8997, 1015, 36249, 33085, 21488, 24050, 38366, 41603, 1657, 8508, 25924, 10174, 11584, 33454, 5010, 8885, 13533, 32554, 37322, 45593, 15421, 48009, 8659, 15315, 49805, 25205, 23164, 39878, 38733, 8686, 41221, 32667, 7078, 40371, 1704, 34500, 39067, 23502, 32060, 29858, 20230, 828, 14422, 36406, 42779, 10684, 43309, 32420, 48324, 31517, 35784, 20574, 46152, 5162, 16984, 9007, 39603, 26335, 46099, 20736, 19118, 25171, 3878, 13674, 2509, 20654, 47609, 48960, 16358, 22489, 28914, 43806, 47565, 43238, 43111, 14805, 17046, 22555, 44012, 10638, 19982, 1112, 23354, 37590, 35357, 3813, 47992, 41316, 9910, 23161, 1440, 32185, 41145, 4018, 1609, 15824, 2946, 14796, 42852, 21408, 4361, 4089, 22605, 43514, 27698, 8903, 14190, 29423, 28522, 9309, 23464, 20444, 11595, 42537, 21549, 47714, 48975, 26780, 25078, 631, 26822, 17284, 34976, 34821, 48210, 45000, 46198, 30320, 49747, 2748, 37010, 8034, 26799, 25578, 11227, 203, 32804, 9058, 40753, 43383, 33681, 48000, 45849, 9710, 5219, 21630, 15556, 11552, 16173, 11065, 48680, 44804, 11030, 47041, 5143, 27995, 39182, 6793, 40665, 41191, 29983, 46537, 9835, 40300, 2624, 16546, 22298, 48366, 48019, 24675, 1786, 41010, 2380, 32528, 5873, 23485, 19184, 44016, 9883, 30023, 15476, 33255, 23318, 10635, 48201, 49347, 26523, 22127, 17684, 32264, 25728, 968, 20366, 34756, 18889, 36074, 30730, 2289, 34851, 37388, 36182, 17199, 45012, 2510, 29879, 25890, 47276, 7865, 26462, 22714, 32506, 3352, 1355, 17894, 48493, 2246, 16640, 44612, 44590, 38142, 46052, 18990, 44964, 49943, 13572, 49977, 34686, 33833, 22300, 25301, 16425, 13695, 7601, 37095, 21590, 15902, 38413, 44162, 47191, 34916, 44651, 23157, 10652, 10030, 21670, 48981, 595, 38334, 3359, 37019, 10234, 22582, 23802, 19083, 41006, 19229, 21168, 32431, 26454, 39367, 28246, 11143, 66, 9224, 37263, 2857, 28959, 8247, 22370, 610, 47292, 31484, 43529, 43439, 16882, 48973, 40121, 12298, 4603, 35971, 27779, 18265, 11392, 34703, 11131, 4147, 43179, 41903, 10315, 7212, 33025, 41427, 35613, 39652, 28484, 17416, 20407, 18675, 893, 28095, 47049, 18378, 16920, 35249, 34554, 36343, 20835, 22430, 12451, 46240, 28291, 9286, 388, 49155, 33511, 10179, 43327, 45966, 36915, 25175, 23654, 30417, 2383, 36804, 26977, 41724, 40247, 49822, 14962, 1028, 23738, 34674, 10388, 44581, 12747, 41347, 23230, 41144, 45881, 32570, 1254, 47901, 48185, 16331, 37457, 15864, 17987, 12133, 49681, 27523, 37561, 29371, 15514, 48761, 46780, 29468, 33351, 46202, 6581, 12339, 10779, 28868, 4274, 27967, 41598, 25869, 17816, 16560, 28653, 49658, 23341, 39956, 21480, 5939, 20120, 32277, 718, 49972, 16420, 13289, 49961, 26076, 25337, 28548, 41639, 41002, 44110, 25510, 45685, 2517, 38187, 30494, 23237, 37276, 8310, 36989, 46562, 18241, 21503, 1592, 26089, 31046, 34189, 8869, 2725, 5340, 37088, 22769, 23659, 294, 4546, 12502, 47008, 7262, 44000, 35430, 30874, 2825, 20613, 1663, 20630, 25732, 8209, 41652, 18027, 26634, 43967, 9314, 39037, 9665, 26489, 20060, 33521, 3922, 10676, 8217, 8778, 31515, 46223, 42067, 46941, 47420, 3061, 47828, 34053, 2848, 36368, 45297, 48768, 45699, 41367, 25379, 11810, 22590, 38396, 5426, 36686, 11431, 17405, 13212, 17102, 21491, 45901, 46443, 16638, 16989, 33910, 29915, 10171, 49589, 29414, 36223, 10015, 2529, 41454, 38371, 11597, 42044, 33569, 2214, 49656, 4695, 12641, 42493, 29920, 15644, 34227, 10445, 46499, 21867, 42939, 8839, 31226, 36432, 3746, 35615, 5401, 33926, 22503, 161, 5242, 6814, 28031, 39815, 23089, 37373, 29594, 22007, 24776, 33580, 23727, 41718, 7788, 8920, 20767, 1489, 11966, 48087, 8198, 1258, 22143, 39811, 12670, 2892, 27121, 42296, 4065, 45799, 20398, 25527, 3423, 39351, 46619, 11020, 23454, 5073, 26753, 3539, 28882, 23263, 39593, 40641, 49575, 16765, 44061, 20299, 36879, 29729, 27015, 11840, 2011, 29735, 17311, 12484, 25405, 4200, 23436, 6311, 8084, 1716, 22989, 1398, 11605, 26461, 45257, 42823, 894, 21155, 36310, 48890, 45537, 32507, 31230, 3389, 35101, 26341, 17186, 1821, 33807, 6272, 5248, 21863, 23497, 6454, 30892, 2167, 10110, 33855, 40994, 2411, 47, 24686, 22130, 10280, 35932, 45611, 9626, 10522, 11443, 10418, 41950, 44553, 15897, 40941, 21513, 1562, 31648, 41014, 44462, 26090, 2894, 14839, 15747, 41659, 18453, 21533, 11142, 15609, 23074, 14813, 10723, 27574, 30336, 23808, 37052, 9043, 25330, 37022, 882, 10626, 38250, 369, 45019, 25552, 47085, 11269, 9756, 1278, 1649, 21189, 33429, 242, 3093, 7333, 37552, 40073, 9679, 10036, 44144, 24895, 1732, 27442, 28590, 37227, 21818, 46609, 9032, 23856, 33439, 14199, 34953, 26239, 4787, 8506, 26722, 37100, 43167, 22976, 6327, 28281, 28576, 16098, 30876, 25018, 14747, 25876, 15732, 42288, 26021, 38101, 4523, 16539, 18079, 34510, 35542, 1423, 39585, 40082, 31100, 15533, 18106, 2641, 40040, 21074, 25609, 41032, 6990, 35027, 3192, 9450, 46758, 25718, 1756, 27593, 47906, 25762, 28374, 6869, 46739, 30191, 39595, 30276, 10576, 11115, 22314, 31087, 26941, 10420, 38679, 18593, 49927, 33001, 7373, 24135, 22637, 9351, 41196, 23437, 30977, 41305, 33994, 49376, 3532, 12824, 16884, 11593, 47412, 38252, 21277, 19401, 24911, 41577, 2717, 19078, 36138, 28259, 2287, 44710, 26905, 17633, 24586, 47702, 13642, 22732, 8792, 8660, 7228, 40182, 23393, 10863, 2046, 28218, 37794, 26109, 30377, 4991, 46581, 46336, 44618, 5100, 27880, 35711, 47592, 36301, 9063, 11090, 10024, 13596, 10778, 14958, 1947, 34426, 8883, 32312, 23394, 40851, 48226, 18876, 46953, 21965, 44839, 7764, 26795, 17155, 10375, 22444, 41155, 21744, 34939, 45557, 9475, 24650, 48483, 48744, 36403, 20004, 15370, 24809, 22709, 25576, 30885, 33524, 20064, 26876, 26627, 6403, 44789, 10093, 9676, 322, 38239, 39024, 41553, 46167, 33889, 7000, 45668, 42425, 45748, 13429, 39045, 42224, 39526, 33649, 7286, 17477, 47967, 40259, 11051, 24632, 5595, 2360, 687, 7562, 23734, 47347, 31503, 20863, 7087, 44300, 29663, 24188, 38289, 45657, 43682, 31885, 14989, 10423, 36807, 36151, 5107, 33291, 11010, 1689, 42153, 10932, 33891, 26797, 39862, 43296, 13636, 28716, 46408, 26543, 17309, 1387, 38498, 8799, 25442, 11228, 28898, 37024, 3516, 24579, 5688, 42208, 38549, 26554, 21923, 15276, 33213, 29853, 2562, 31453, 40632, 6671, 17608, 33259, 32130, 36096, 42269, 25827, 17387, 11863, 15058, 35455, 23876, 10455, 19821, 39902, 9413, 29944, 4511, 4488, 31333, 25771, 37101, 26868, 36447, 6045, 17401, 31607, 7266, 19444, 9245, 23557, 6170, 9085, 43151, 3716, 43617, 8965, 38436, 36616, 462, 2166, 26499, 36587, 45861, 49501, 39434, 32135, 46800, 45247, 7015, 30996, 36670, 22759, 22481, 6391, 44940, 337, 15839, 14853, 20414, 17986, 14720, 587, 32481, 23256, 33356, 22339, 6007, 5079, 19973, 37595, 27675, 14827, 48428, 24084, 24979, 49688, 9533, 15180, 18867, 13062, 48653, 31530, 43254, 23538, 18540, 25188, 40135, 8478, 7828, 26292, 23269, 32784, 30865, 14984, 43003, 46484, 24506, 41429, 23511, 28306, 18180, 23541, 26271, 46816, 18553, 31439, 19094, 7905, 29228, 10109, 22545, 15960, 48714, 12251, 22157, 32722, 14987, 7207, 44636, 25159, 25474, 30462, 33654, 30262, 37086, 40507, 14460, 44278, 26167, 32913, 20395, 31894, 15247, 20612, 33942, 44821, 107, 6022, 30917, 20784, 25838, 14901, 28269, 3186, 37708, 2650, 26640, 17266, 13126, 47541, 21417, 11702, 7412, 11850, 45786, 23865, 1852, 15317, 2863, 530, 35034, 295, 8497, 7634, 39626, 39706, 13065, 5345, 48566, 30545, 12956, 97, 34093, 40723, 27210, 4376, 35188, 11608, 15355, 14873, 27225, 25030, 31108, 24, 28561, 13769, 24985, 2699, 40354, 17650, 1871, 38195, 22745, 46127, 24082, 22106, 44379, 29747, 41992, 8806, 39053, 33884, 6032, 16496, 6767, 46847, 6782, 17882, 1581, 45373, 9299, 40685, 43178, 8906, 24832, 13571, 37563, 43255, 20941, 13215, 27601, 33293, 32792, 7886, 36673, 6916, 45424, 31104, 8162, 33357, 29339, 30788, 11709, 29812, 35898, 22270, 8446, 27277, 16674, 24722, 37026, 33124, 21993, 15306, 29740, 16283, 23006, 31493, 26888, 1567, 29294, 47409, 393, 36206, 26532, 29234, 14678, 28146, 15798, 16594, 31275, 31135, 9240, 14959, 28895, 18580, 23591, 42814, 31862, 39285, 9752, 34234, 44859, 5738, 12294, 19654, 33934, 41346, 44116, 8044, 3866, 10165, 22466, 2404, 21917, 40749, 10509, 30710, 44419, 12296, 26966, 32512, 12586, 10978, 25617, 3088, 22214, 49796, 44701, 34138, 12297, 47443, 21499, 12006, 34026, 35571, 46699, 38960, 28445, 9971, 41519, 45136, 40480, 32338, 37403, 13983, 39194, 28926, 2156, 15923, 31965, 39581, 20819, 36426, 47913, 12870, 33, 2853, 15915, 29046, 44184, 39975, 14679, 43308, 44860, 7146, 49626, 33798, 27887, 42318, 41554, 18769, 44762, 22160, 32337, 44921, 12592, 10696, 24421, 36527, 23365, 47022, 28714, 25612, 28763, 43465, 20809, 30708, 4412]
2024-11-17:14:43:20 [INFO    ] [fp.py:303] Forwarding all the training dataset:
2024-11-17:14:43:28 [INFO    ] [fp.py:316] get seq_sort, (len=768), seq_sort:tensor([674, 747, 187,  70, 497, 196, 124, 168,  54, 583, 431, 475, 592, 712,
        752, 161, 690, 487, 472, 249,  28, 208, 357, 590,  95,  58, 235,  77,
        379, 744, 622, 227, 630, 442,  11, 143, 114, 734,  98, 616, 718,  34,
        151, 520, 407, 123, 540, 459, 265, 426, 461, 213, 664,  47, 144, 139,
        409, 382, 629,  19, 353, 751, 324,  87, 599,  66, 678, 202,  67, 764,
        710, 390, 115, 360, 658, 567, 395, 498, 584, 512, 683, 279, 322, 305,
        510, 597,  65, 534, 377, 293, 301, 397, 236, 112, 103, 699, 702,  82,
          0, 286, 118, 269, 569, 177, 692, 226, 104, 572, 760, 456, 232, 217,
        565, 441, 640, 287, 739, 688, 515,  94, 330, 489, 223, 388, 215,  76,
        700, 553,  35,   2, 749,   9, 160, 705, 533,  72, 603, 203, 581, 624,
        672,  39, 635, 376, 190, 364, 673,  75, 133, 766, 731, 573, 725, 336,
        550,  25, 715, 754, 636, 337,   4, 153, 272, 737, 122, 600, 276, 652,
        568,  21, 231, 244,  83, 381, 393, 185, 119, 647, 677, 308, 204, 164,
        736, 243, 209,  62, 389, 486,  24, 566, 399, 422, 251, 141, 296, 169,
        320, 655, 601, 146, 644, 447, 245,  12,  68, 140, 499, 493, 221, 327,
        120, 418, 167, 219, 348,  64, 680,  15,  23,  52, 642, 193, 740, 484,
        439, 261, 437, 340, 129, 611, 558, 273, 519, 214, 351, 421, 192, 666,
        619, 344,  90, 145, 480, 234, 241, 638,  18,  38, 408,  63, 617, 420,
        525, 384, 325,  29, 354,  16, 401,  50, 228,  49, 206, 735, 253, 128,
        561, 242, 257, 247, 578, 479, 453, 238, 299, 392, 291, 693, 152,   6,
        477, 552, 342, 345, 304,   7, 250, 576, 637, 465, 613, 676, 302, 414,
        445, 373, 436, 156,  33, 346, 300, 106, 444, 176, 724, 596, 730, 386,
        462, 753, 102, 482, 290,  57,  61, 761, 313, 108, 516,  55, 333,  37,
        343, 130,  13, 563, 416, 651, 288, 494, 755, 518, 586,  56, 478, 530,
         73, 406, 385, 256, 554, 721, 610, 252, 150, 526, 696, 375, 691, 285,
        450, 237, 481, 309, 523, 332, 220, 186, 723, 435, 591, 682, 659, 341,
         30, 508, 759, 709, 312,  43, 359,  32, 455, 166, 248, 675, 311,  14,
        295, 495, 681, 667, 371, 263, 404, 268, 469, 531,  59,  85,  79, 262,
        402,  80, 361, 684,  86, 706, 254, 411, 697, 645, 750, 270, 555,  96,
        745, 417, 197, 714, 188, 733, 126, 743, 317,  91, 358, 757, 109, 545,
        537, 521, 542, 315, 538, 609, 632, 323,  51,  78, 294, 729, 116, 430,
        485, 641, 387, 260, 564, 199, 230, 367, 195, 136, 686, 275, 514,  46,
        663, 380, 722, 529, 657, 135, 606, 274, 536, 585, 396, 557, 398, 443,
        446, 391,   5,  27, 424, 162, 711, 483, 670, 449, 460, 595, 171, 650,
        194,  40, 698, 205,  45, 653,  41, 467, 618, 183, 307, 464,  92, 314,
        570, 201, 748, 148,  84, 362, 679,  81, 278,  20, 575, 239, 454, 732,
        509, 631, 163, 548, 604, 355, 281, 369, 366, 506, 560, 704, 614, 607,
        427, 524, 602, 528, 593,  10, 758, 259, 174, 656, 419, 211, 612, 400,
        423, 476, 319, 522, 501, 229, 507, 173, 582, 403,  60, 405, 615, 543,
        365, 689,  31, 634, 626, 297, 283, 180, 463, 266, 546, 620, 457, 589,
        352, 184,  22, 189,  93, 175, 429, 394, 258, 588, 432, 310, 425, 471,
        470, 466,   1, 669, 142, 551, 383, 347, 717, 716, 374, 255, 165, 298,
        579, 198, 210, 412, 594, 200, 113, 284,  69, 504, 339, 605, 137, 105,
        428, 580, 326, 329, 264, 182, 363, 110, 703, 665, 726, 649, 433, 147,
        292, 623, 434, 271,  36, 671,  53, 685, 633, 648, 218, 372, 328, 492,
        503, 527, 639, 318, 654, 179, 701, 240, 708, 111, 306, 627,  42, 191,
        303, 207, 720, 661, 121, 621, 224, 338, 154, 289, 502, 468, 532,  89,
         74, 598, 738, 742, 535, 225, 728, 765, 694, 496, 316, 625, 707, 448,
        282,  71,  17, 539, 440, 350, 170, 741, 413, 415,   3, 159, 762, 587,
         99, 331, 368, 216, 727, 233, 277, 335, 157,   8, 132, 488, 125, 438,
        117, 646, 131, 541, 767, 668, 349, 212, 321, 544, 513, 267, 608, 756,
        660,  97, 138, 155, 556, 746,  26, 474, 577, 378, 628, 713, 452,  44,
        222, 500, 695, 101, 107, 134, 451, 410, 473, 505, 763, 643, 662, 547,
        491, 181, 490, 687, 178, 100, 280, 559, 158, 549, 334, 458,  88, 149,
         48, 574, 246, 517, 172, 719, 571, 370, 127, 511, 356, 562],
       device='cuda:0')
2024-11-17:14:43:28 [INFO    ] [fp.py:323] Find the first child be nn.Linear, name:
2024-11-17:14:44:38 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 0,
 'test_acc': 0.8682,
 'test_asr': 0.8944444444444445,
 'test_ra': 0.10411111111111111}
2024-11-17:14:45:48 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 8,
 'test_acc': 0.8678,
 'test_asr': 0.8933333333333333,
 'test_ra': 0.10533333333333333}
2024-11-17:14:46:58 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 16,
 'test_acc': 0.8679,
 'test_asr': 0.8942222222222223,
 'test_ra': 0.10444444444444445}
2024-11-17:14:48:09 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 24,
 'test_acc': 0.868,
 'test_asr': 0.8956666666666667,
 'test_ra': 0.10311111111111111}
2024-11-17:14:49:19 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 32,
 'test_acc': 0.8681,
 'test_asr': 0.8961111111111111,
 'test_ra': 0.10266666666666667}
2024-11-17:14:50:29 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 40,
 'test_acc': 0.868,
 'test_asr': 0.8957777777777778,
 'test_ra': 0.103}
2024-11-17:14:51:39 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 48,
 'test_acc': 0.8683,
 'test_asr': 0.8955555555555555,
 'test_ra': 0.10322222222222223}
2024-11-17:14:52:49 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 56,
 'test_acc': 0.8681,
 'test_asr': 0.8967777777777778,
 'test_ra': 0.102}
2024-11-17:14:54:00 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 64,
 'test_acc': 0.8682,
 'test_asr': 0.8975555555555556,
 'test_ra': 0.10122222222222223}
2024-11-17:14:55:10 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 72,
 'test_acc': 0.8679,
 'test_asr': 0.8968888888888888,
 'test_ra': 0.102}
2024-11-17:14:56:20 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 80,
 'test_acc': 0.8682,
 'test_asr': 0.8965555555555556,
 'test_ra': 0.10222222222222223}
2024-11-17:14:57:30 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 88,
 'test_acc': 0.8682,
 'test_asr': 0.8973333333333333,
 'test_ra': 0.10155555555555555}
2024-11-17:14:58:41 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 96,
 'test_acc': 0.8678,
 'test_asr': 0.8973333333333333,
 'test_ra': 0.10155555555555555}
2024-11-17:14:59:51 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 104,
 'test_acc': 0.868,
 'test_asr': 0.8984444444444445,
 'test_ra': 0.10044444444444445}
2024-11-17:15:01:01 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 112,
 'test_acc': 0.8685,
 'test_asr': 0.8981111111111111,
 'test_ra': 0.10077777777777777}
2024-11-17:15:02:11 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 120,
 'test_acc': 0.8681,
 'test_asr': 0.8961111111111111,
 'test_ra': 0.10277777777777777}
2024-11-17:15:03:22 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 128,
 'test_acc': 0.8683,
 'test_asr': 0.8952222222222223,
 'test_ra': 0.10366666666666667}
2024-11-17:15:04:32 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 136,
 'test_acc': 0.8682,
 'test_asr': 0.8943333333333333,
 'test_ra': 0.10455555555555555}
2024-11-17:15:05:42 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 144,
 'test_acc': 0.8683,
 'test_asr': 0.8947777777777778,
 'test_ra': 0.10411111111111111}
2024-11-17:15:06:53 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 152,
 'test_acc': 0.8678,
 'test_asr': 0.8945555555555555,
 'test_ra': 0.10433333333333333}
2024-11-17:15:08:03 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 160,
 'test_acc': 0.8682,
 'test_asr': 0.8955555555555555,
 'test_ra': 0.10333333333333333}
2024-11-17:15:09:13 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 168,
 'test_acc': 0.8681,
 'test_asr': 0.8974444444444445,
 'test_ra': 0.10144444444444445}
2024-11-17:15:10:23 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 176,
 'test_acc': 0.8677,
 'test_asr': 0.8964444444444445,
 'test_ra': 0.10244444444444445}
2024-11-17:15:11:34 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 184,
 'test_acc': 0.868,
 'test_asr': 0.8958888888888888,
 'test_ra': 0.103}
2024-11-17:15:12:44 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 192,
 'test_acc': 0.8684,
 'test_asr': 0.895,
 'test_ra': 0.10377777777777777}
2024-11-17:15:13:54 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 200,
 'test_acc': 0.8678,
 'test_asr': 0.8935555555555555,
 'test_ra': 0.10511111111111111}
2024-11-17:15:15:04 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 208,
 'test_acc': 0.8681,
 'test_asr': 0.8938888888888888,
 'test_ra': 0.10477777777777778}
2024-11-17:15:16:15 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 216,
 'test_acc': 0.8683,
 'test_asr': 0.8954444444444445,
 'test_ra': 0.10322222222222223}
2024-11-17:15:17:25 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 224,
 'test_acc': 0.8679,
 'test_asr': 0.8967777777777778,
 'test_ra': 0.102}
2024-11-17:15:18:35 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 232,
 'test_acc': 0.8685,
 'test_asr': 0.8957777777777778,
 'test_ra': 0.103}
2024-11-17:15:19:45 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 240,
 'test_acc': 0.8682,
 'test_asr': 0.8972222222222223,
 'test_ra': 0.10155555555555555}
2024-11-17:15:20:56 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 248,
 'test_acc': 0.8679,
 'test_asr': 0.8974444444444445,
 'test_ra': 0.10133333333333333}
2024-11-17:15:22:06 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 256,
 'test_acc': 0.8678,
 'test_asr': 0.8975555555555556,
 'test_ra': 0.10122222222222223}
2024-11-17:15:23:16 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 264,
 'test_acc': 0.8683,
 'test_asr': 0.9002222222222223,
 'test_ra': 0.09855555555555555}
2024-11-17:15:24:27 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 272,
 'test_acc': 0.8678,
 'test_asr': 0.8957777777777778,
 'test_ra': 0.10277777777777777}
2024-11-17:15:25:37 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 280,
 'test_acc': 0.8678,
 'test_asr': 0.8966666666666666,
 'test_ra': 0.10188888888888889}
2024-11-17:15:26:47 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 288,
 'test_acc': 0.8677,
 'test_asr': 0.8965555555555556,
 'test_ra': 0.102}
2024-11-17:15:27:57 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 296,
 'test_acc': 0.8676,
 'test_asr': 0.8954444444444445,
 'test_ra': 0.103}
2024-11-17:15:29:08 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 304,
 'test_acc': 0.8675,
 'test_asr': 0.8954444444444445,
 'test_ra': 0.103}
2024-11-17:15:30:18 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 312,
 'test_acc': 0.8676,
 'test_asr': 0.8966666666666666,
 'test_ra': 0.10177777777777777}
2024-11-17:15:31:28 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 320,
 'test_acc': 0.8674,
 'test_asr': 0.896,
 'test_ra': 0.10244444444444445}
2024-11-17:15:32:38 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 328,
 'test_acc': 0.8673,
 'test_asr': 0.8968888888888888,
 'test_ra': 0.10155555555555555}
2024-11-17:15:33:49 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 336,
 'test_acc': 0.8673,
 'test_asr': 0.8977777777777778,
 'test_ra': 0.10088888888888889}
2024-11-17:15:34:59 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 344,
 'test_acc': 0.8669,
 'test_asr': 0.8975555555555556,
 'test_ra': 0.101}
2024-11-17:15:36:09 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 352,
 'test_acc': 0.8668,
 'test_asr': 0.8958888888888888,
 'test_ra': 0.10255555555555555}
2024-11-17:15:37:20 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 360,
 'test_acc': 0.867,
 'test_asr': 0.8961111111111111,
 'test_ra': 0.10233333333333333}
2024-11-17:15:38:30 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 368,
 'test_acc': 0.867,
 'test_asr': 0.8967777777777778,
 'test_ra': 0.10166666666666667}
2024-11-17:15:39:40 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 376,
 'test_acc': 0.8671,
 'test_asr': 0.8978888888888888,
 'test_ra': 0.10055555555555555}
2024-11-17:15:40:50 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 384,
 'test_acc': 0.8669,
 'test_asr': 0.8992222222222223,
 'test_ra': 0.09944444444444445}
2024-11-17:15:42:00 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 392,
 'test_acc': 0.867,
 'test_asr': 0.899,
 'test_ra': 0.09955555555555555}
2024-11-17:15:43:11 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 400,
 'test_acc': 0.867,
 'test_asr': 0.895,
 'test_ra': 0.10355555555555555}
2024-11-17:15:44:21 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 408,
 'test_acc': 0.8666,
 'test_asr': 0.8976666666666666,
 'test_ra': 0.101}
2024-11-17:15:45:31 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 416,
 'test_acc': 0.8668,
 'test_asr': 0.8963333333333333,
 'test_ra': 0.10233333333333333}
2024-11-17:15:46:42 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 424,
 'test_acc': 0.8667,
 'test_asr': 0.8975555555555556,
 'test_ra': 0.10122222222222223}
2024-11-17:15:47:52 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 432,
 'test_acc': 0.8665,
 'test_asr': 0.8942222222222223,
 'test_ra': 0.10433333333333333}
2024-11-17:15:49:02 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 440,
 'test_acc': 0.8664,
 'test_asr': 0.8945555555555555,
 'test_ra': 0.104}
2024-11-17:15:50:12 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 448,
 'test_acc': 0.8663,
 'test_asr': 0.8966666666666666,
 'test_ra': 0.10177777777777777}
2024-11-17:15:51:23 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 456,
 'test_acc': 0.8664,
 'test_asr': 0.8965555555555556,
 'test_ra': 0.10188888888888889}
2024-11-17:15:52:33 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 464,
 'test_acc': 0.8667,
 'test_asr': 0.8963333333333333,
 'test_ra': 0.102}
2024-11-17:15:53:43 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 472,
 'test_acc': 0.8665,
 'test_asr': 0.8963333333333333,
 'test_ra': 0.102}
2024-11-17:15:54:54 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 480,
 'test_acc': 0.8662,
 'test_asr': 0.8961111111111111,
 'test_ra': 0.10211111111111111}
2024-11-17:15:56:04 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 488,
 'test_acc': 0.8662,
 'test_asr': 0.8955555555555555,
 'test_ra': 0.10266666666666667}
2024-11-17:15:57:14 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 496,
 'test_acc': 0.8663,
 'test_asr': 0.8968888888888888,
 'test_ra': 0.10133333333333333}
2024-11-17:15:58:24 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 504,
 'test_acc': 0.866,
 'test_asr': 0.8952222222222223,
 'test_ra': 0.103}
2024-11-17:15:59:35 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 512,
 'test_acc': 0.8668,
 'test_asr': 0.8954444444444445,
 'test_ra': 0.10277777777777777}
2024-11-17:16:00:45 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 520,
 'test_acc': 0.8672,
 'test_asr': 0.8971111111111111,
 'test_ra': 0.10111111111111111}
2024-11-17:16:01:55 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 528,
 'test_acc': 0.8671,
 'test_asr': 0.8967777777777778,
 'test_ra': 0.10133333333333333}
2024-11-17:16:03:06 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 536,
 'test_acc': 0.8666,
 'test_asr': 0.8968888888888888,
 'test_ra': 0.10133333333333333}
2024-11-17:16:04:16 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 544,
 'test_acc': 0.8662,
 'test_asr': 0.8993333333333333,
 'test_ra': 0.09877777777777778}
2024-11-17:16:05:26 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 552,
 'test_acc': 0.8662,
 'test_asr': 0.8986666666666666,
 'test_ra': 0.09977777777777778}
2024-11-17:16:06:36 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 560,
 'test_acc': 0.8661,
 'test_asr': 0.8985555555555556,
 'test_ra': 0.09955555555555555}
2024-11-17:16:07:47 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 568,
 'test_acc': 0.8656,
 'test_asr': 0.8984444444444445,
 'test_ra': 0.09966666666666667}
2024-11-17:16:08:57 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 576,
 'test_acc': 0.8657,
 'test_asr': 0.8997777777777778,
 'test_ra': 0.09844444444444445}
2024-11-17:16:10:07 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 584,
 'test_acc': 0.8658,
 'test_asr': 0.9024444444444445,
 'test_ra': 0.09566666666666666}
2024-11-17:16:11:17 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 592,
 'test_acc': 0.8661,
 'test_asr': 0.9026666666666666,
 'test_ra': 0.09544444444444444}
2024-11-17:16:12:28 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 600,
 'test_acc': 0.8649,
 'test_asr': 0.9044444444444445,
 'test_ra': 0.09366666666666666}
2024-11-17:16:13:38 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 608,
 'test_acc': 0.8659,
 'test_asr': 0.9045555555555556,
 'test_ra': 0.09366666666666666}
2024-11-17:16:14:48 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 616,
 'test_acc': 0.8645,
 'test_asr': 0.9075555555555556,
 'test_ra': 0.09066666666666667}
2024-11-17:16:15:59 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 624,
 'test_acc': 0.8641,
 'test_asr': 0.9091111111111111,
 'test_ra': 0.08911111111111111}
2024-11-17:16:17:09 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 632,
 'test_acc': 0.8642,
 'test_asr': 0.912,
 'test_ra': 0.08622222222222223}
2024-11-17:16:18:19 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 640,
 'test_acc': 0.8638,
 'test_asr': 0.9197777777777778,
 'test_ra': 0.07844444444444444}
2024-11-17:16:19:29 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 648,
 'test_acc': 0.8633,
 'test_asr': 0.922,
 'test_ra': 0.07622222222222222}
2024-11-17:16:20:40 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 656,
 'test_acc': 0.8618,
 'test_asr': 0.9186666666666666,
 'test_ra': 0.07933333333333334}
2024-11-17:16:21:50 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 664,
 'test_acc': 0.8612,
 'test_asr': 0.9172222222222223,
 'test_ra': 0.08077777777777778}
2024-11-17:16:23:00 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 672,
 'test_acc': 0.8611,
 'test_asr': 0.9187777777777778,
 'test_ra': 0.0791111111111111}
2024-11-17:16:24:10 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 680,
 'test_acc': 0.8603,
 'test_asr': 0.9162222222222223,
 'test_ra': 0.08155555555555556}
2024-11-17:16:25:21 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 688,
 'test_acc': 0.8605,
 'test_asr': 0.909,
 'test_ra': 0.08888888888888889}
2024-11-17:16:26:31 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 696,
 'test_acc': 0.8557,
 'test_asr': 0.9053333333333333,
 'test_ra': 0.09244444444444444}
2024-11-17:16:27:41 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 704,
 'test_acc': 0.8541,
 'test_asr': 0.9073333333333333,
 'test_ra': 0.0898888888888889}
2024-11-17:16:28:52 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 712,
 'test_acc': 0.8547,
 'test_asr': 0.9198888888888889,
 'test_ra': 0.07744444444444444}
2024-11-17:16:30:02 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 720,
 'test_acc': 0.8536,
 'test_asr': 0.9292222222222222,
 'test_ra': 0.06822222222222223}
2024-11-17:16:31:12 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 728,
 'test_acc': 0.8459,
 'test_asr': 0.924,
 'test_ra': 0.07266666666666667}
2024-11-17:16:32:22 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 736,
 'test_acc': 0.8422,
 'test_asr': 0.9076666666666666,
 'test_ra': 0.08844444444444445}
2024-11-17:16:33:33 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 744,
 'test_acc': 0.8328,
 'test_asr': 0.9047777777777778,
 'test_ra': 0.09066666666666667}
2024-11-17:16:34:43 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 752,
 'test_acc': 0.827,
 'test_asr': 0.849,
 'test_ra': 0.13833333333333334}
2024-11-17:16:35:53 [INFO    ] [trainer_cls.py:65] {'all_filter_num': 768,
 'num_pruned': 760,
 'test_acc': 0.6972,
 'test_asr': 0.8546666666666667,
 'test_ra': 0.08811111111111111}
2024-11-17:16:35:53 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:35:53 [DEBUG   ] [trainer_cls.py:88] return df with np.nan and None converted by str()
2024-11-17:16:35:53 [DEBUG   ] [pyplot.py:414] Loaded backend agg version v2.2.
2024-11-17:16:35:53 [INFO    ] [fp.py:395] End prune. Pruned 760/768 test_acc:0.70  test_asr:0.85  test_ra:0.09  
2024-11-17:16:35:54 [DEBUG   ] [trainer_cls.py:1765] This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
2024-11-17:16:35:54 [INFO    ] [trainer_cls.py:972] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2024-11-17:16:35:54 [INFO    ] [trainer_cls.py:1030] ('epoch_now:0, '
 'batch_now:0self.amp:True,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    differentiable: False\n'
 '    foreach: None\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, 'verbose': False, '_step_count': 1, "
 "'_get_lr_called_within_step': False, '_last_lr': "
 "[0.01]},self.scaler:{'scale': 65536.0, 'growth_factor': 2.0, "
 "'backoff_factor': 0.5, 'growth_interval': 2000, '_growth_tracker': 0})")
2024-11-17:16:35:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.565240144729614 s
2024-11-17:16:35:59 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:35:59 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:36:46 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 1.962168190214369,
 'clean_test_loss_avg_over_batch': 1.8621757954359055,
 'epoch': 0,
 'test_acc': 0.7482,
 'test_asr': 0.7458888888888889,
 'test_ra': 0.16311111111111112,
 'train_acc': 0.7712,
 'train_acc_clean_only': 0.7712,
 'train_epoch_loss_avg_over_batch': 2.043047749996185}
2024-11-17:16:36:47 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:36:47 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:36:47 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:36:47 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:36:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.683920621871948 s
2024-11-17:16:36:52 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:36:52 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:37:39 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 1.8187935915258195,
 'clean_test_loss_avg_over_batch': 1.2595140308141708,
 'epoch': 1,
 'test_acc': 0.8173,
 'test_asr': 0.6455555555555555,
 'test_ra': 0.20644444444444446,
 'train_acc': 0.824,
 'train_acc_clean_only': 0.824,
 'train_epoch_loss_avg_over_batch': 1.578284704685211}
2024-11-17:16:37:39 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:37:39 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:37:40 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:37:40 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:37:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.684397459030151 s
2024-11-17:16:37:45 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:37:45 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:38:32 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 1.709123667743471,
 'clean_test_loss_avg_over_batch': 0.6970538273453712,
 'epoch': 2,
 'test_acc': 0.8906,
 'test_asr': 0.6386666666666667,
 'test_ra': 0.26455555555555554,
 'train_acc': 0.8916,
 'train_acc_clean_only': 0.8916,
 'train_epoch_loss_avg_over_batch': 0.9372730731964112}
2024-11-17:16:38:32 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:38:32 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:38:32 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:38:33 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:38:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.674201011657715 s
2024-11-17:16:38:38 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:38:38 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:39:25 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 1.4384787811173334,
 'clean_test_loss_avg_over_batch': 0.38544782623648643,
 'epoch': 3,
 'test_acc': 0.9141,
 'test_asr': 0.7016666666666667,
 'test_ra': 0.23222222222222222,
 'train_acc': 0.9372,
 'train_acc_clean_only': 0.9372,
 'train_epoch_loss_avg_over_batch': 0.46190168559551237}
2024-11-17:16:39:25 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:39:25 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:39:25 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:39:26 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:39:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.6869542598724365 s
2024-11-17:16:39:31 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:39:31 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:40:18 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 1.1527016295327082,
 'clean_test_loss_avg_over_batch': 0.2747817225754261,
 'epoch': 4,
 'test_acc': 0.9315,
 'test_asr': 0.7705555555555555,
 'test_ra': 0.17055555555555554,
 'train_acc': 0.9692,
 'train_acc_clean_only': 0.9692,
 'train_epoch_loss_avg_over_batch': 0.228633913397789}
2024-11-17:16:40:18 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:40:18 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:40:18 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:40:19 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:40:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.673661947250366 s
2024-11-17:16:40:24 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:40:24 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:41:11 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.9365686492787467,
 'clean_test_loss_avg_over_batch': 0.21516806222498416,
 'epoch': 5,
 'test_acc': 0.9428,
 'test_asr': 0.8142222222222222,
 'test_ra': 0.14766666666666667,
 'train_acc': 0.974,
 'train_acc_clean_only': 0.974,
 'train_epoch_loss_avg_over_batch': 0.14017515853047371}
2024-11-17:16:41:11 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:41:11 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:41:11 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:41:12 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:41:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.670206069946289 s
2024-11-17:16:41:17 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:41:17 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:42:04 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.8548982888460159,
 'clean_test_loss_avg_over_batch': 0.18377532437443733,
 'epoch': 6,
 'test_acc': 0.9459,
 'test_asr': 0.8328888888888889,
 'test_ra': 0.1398888888888889,
 'train_acc': 0.9828,
 'train_acc_clean_only': 0.9828,
 'train_epoch_loss_avg_over_batch': 0.08735063672065735}
2024-11-17:16:42:04 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:42:04 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:42:04 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:42:04 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:42:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.6805925369262695 s
2024-11-17:16:42:10 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:42:10 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:42:57 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5899540475673146,
 'clean_test_loss_avg_over_batch': 0.2014121700078249,
 'epoch': 7,
 'test_acc': 0.9467,
 'test_asr': 0.8957777777777778,
 'test_ra': 0.092,
 'train_acc': 0.9876,
 'train_acc_clean_only': 0.9876,
 'train_epoch_loss_avg_over_batch': 0.057294242456555365}
2024-11-17:16:42:57 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:42:57 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:42:57 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:42:57 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:43:03 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.6739466190338135 s
2024-11-17:16:43:03 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:43:03 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:43:50 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5685363353954421,
 'clean_test_loss_avg_over_batch': 0.18263285607099533,
 'epoch': 8,
 'test_acc': 0.9503,
 'test_asr': 0.8982222222222223,
 'test_ra': 0.08844444444444445,
 'train_acc': 0.9936,
 'train_acc_clean_only': 0.9936,
 'train_epoch_loss_avg_over_batch': 0.03981486074626446}
2024-11-17:16:43:50 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:43:50 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:43:50 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:43:50 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:43:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.668470859527588 s
2024-11-17:16:43:56 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:43:56 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:44:43 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.6290886940227615,
 'clean_test_loss_avg_over_batch': 0.1765865845605731,
 'epoch': 9,
 'test_acc': 0.9511,
 'test_asr': 0.8821111111111111,
 'test_ra': 0.10633333333333334,
 'train_acc': 0.9932,
 'train_acc_clean_only': 0.9932,
 'train_epoch_loss_avg_over_batch': 0.03341144025325775}
2024-11-17:16:44:43 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:44:43 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:44:43 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:44:43 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:44:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.673750400543213 s
2024-11-17:16:44:49 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:44:49 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:45:36 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5785880618625217,
 'clean_test_loss_avg_over_batch': 0.16571491388604045,
 'epoch': 10,
 'test_acc': 0.9532,
 'test_asr': 0.8922222222222222,
 'test_ra': 0.09633333333333334,
 'train_acc': 0.9932,
 'train_acc_clean_only': 0.9932,
 'train_epoch_loss_avg_over_batch': 0.03218733295798302}
2024-11-17:16:45:36 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:45:36 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:45:36 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:45:36 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:45:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.675928354263306 s
2024-11-17:16:45:41 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:45:41 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:46:28 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.6237369337015681,
 'clean_test_loss_avg_over_batch': 0.1676214599981904,
 'epoch': 11,
 'test_acc': 0.9556,
 'test_asr': 0.8793333333333333,
 'test_ra': 0.11,
 'train_acc': 0.9956,
 'train_acc_clean_only': 0.9956,
 'train_epoch_loss_avg_over_batch': 0.02567277904599905}
2024-11-17:16:46:29 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:46:29 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:46:29 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:46:29 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:46:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.66946268081665 s
2024-11-17:16:46:34 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:46:34 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:47:21 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5600612875488069,
 'clean_test_loss_avg_over_batch': 0.1717218954116106,
 'epoch': 12,
 'test_acc': 0.9552,
 'test_asr': 0.8914444444444445,
 'test_ra': 0.09977777777777778,
 'train_acc': 0.9964,
 'train_acc_clean_only': 0.9964,
 'train_epoch_loss_avg_over_batch': 0.01828022925183177}
2024-11-17:16:47:21 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:47:21 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:47:22 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:47:22 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:47:27 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.673221111297607 s
2024-11-17:16:47:27 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:47:27 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:48:14 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5587213362256686,
 'clean_test_loss_avg_over_batch': 0.16263962741941212,
 'epoch': 13,
 'test_acc': 0.9555,
 'test_asr': 0.8906666666666667,
 'test_ra': 0.10122222222222223,
 'train_acc': 0.9988,
 'train_acc_clean_only': 0.9988,
 'train_epoch_loss_avg_over_batch': 0.015117106214165687}
2024-11-17:16:48:14 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:48:14 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:48:14 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:48:15 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:48:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.650327444076538 s
2024-11-17:16:48:20 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:48:20 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:49:07 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5782803636458185,
 'clean_test_loss_avg_over_batch': 0.16303759920410812,
 'epoch': 14,
 'test_acc': 0.9565,
 'test_asr': 0.8858888888888888,
 'test_ra': 0.10677777777777778,
 'train_acc': 0.9992,
 'train_acc_clean_only': 0.9992,
 'train_epoch_loss_avg_over_batch': 0.012744063604623079}
2024-11-17:16:49:07 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:49:07 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:49:07 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:49:08 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:49:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.666717052459717 s
2024-11-17:16:49:13 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:49:13 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:50:00 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5595890821682082,
 'clean_test_loss_avg_over_batch': 0.16396204605698586,
 'epoch': 15,
 'test_acc': 0.9566,
 'test_asr': 0.887,
 'test_ra': 0.10611111111111111,
 'train_acc': 0.9996,
 'train_acc_clean_only': 0.9996,
 'train_epoch_loss_avg_over_batch': 0.01079108500853181}
2024-11-17:16:50:00 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:50:00 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:50:00 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:50:00 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:50:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.659985065460205 s
2024-11-17:16:50:06 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:50:06 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:50:53 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5655418137709299,
 'clean_test_loss_avg_over_batch': 0.15880755453836173,
 'epoch': 16,
 'test_acc': 0.9572,
 'test_asr': 0.8837777777777778,
 'test_ra': 0.10888888888888888,
 'train_acc': 0.9996,
 'train_acc_clean_only': 0.9996,
 'train_epoch_loss_avg_over_batch': 0.009089894592761993}
2024-11-17:16:50:53 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:50:53 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:50:53 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:50:53 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:50:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.669249534606934 s
2024-11-17:16:50:59 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:50:59 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:51:46 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.5891312650508351,
 'clean_test_loss_avg_over_batch': 0.16390972770750523,
 'epoch': 17,
 'test_acc': 0.9586,
 'test_asr': 0.8817777777777778,
 'test_ra': 0.11177777777777778,
 'train_acc': 0.9992,
 'train_acc_clean_only': 0.9992,
 'train_epoch_loss_avg_over_batch': 0.00930515001527965}
2024-11-17:16:51:46 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:51:46 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:51:46 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:51:46 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:51:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.666387557983398 s
2024-11-17:16:51:52 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:51:52 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:52:39 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.6045402056641049,
 'clean_test_loss_avg_over_batch': 0.15522948066936806,
 'epoch': 18,
 'test_acc': 0.9598,
 'test_asr': 0.8802222222222222,
 'test_ra': 0.11344444444444444,
 'train_acc': 0.9996,
 'train_acc_clean_only': 0.9996,
 'train_epoch_loss_avg_over_batch': 0.007544607017189264}
2024-11-17:16:52:39 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:52:39 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:52:39 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:52:39 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:52:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 5.652415037155151 s
2024-11-17:16:52:44 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:52:44 [WARNING ] [trainer_cls.py:590] zero len array in func all_acc(), return None!
2024-11-17:16:53:31 [INFO    ] [trainer_cls.py:65] {'batch': 10,
 'bd_test_loss_avg_over_batch': 0.6102400256527795,
 'clean_test_loss_avg_over_batch': 0.1557630890980363,
 'epoch': 19,
 'test_acc': 0.9596,
 'test_asr': 0.8788888888888889,
 'test_ra': 0.115,
 'train_acc': 0.9996,
 'train_acc_clean_only': 0.9996,
 'train_epoch_loss_avg_over_batch': 0.006863575242459774}
2024-11-17:16:53:32 [WARNING ] [trainer_cls.py:916] train_asr_list contains None, or len not match
2024-11-17:16:53:32 [WARNING ] [trainer_cls.py:920] train_ra_list contains None, or len not match
2024-11-17:16:53:32 [DEBUG   ] [trainer_cls.py:72] return df with np.nan and None converted by str()
2024-11-17:16:53:32 [DEBUG   ] [trainer_cls.py:88] return df with np.nan and None converted by str()
2024-11-17:16:53:32 [INFO    ] [save_load_attack.py:176] saving...
2024-11-17:16:53:32 [DEBUG   ] [save_load_attack.py:177] location : record/sig_0_1_ViT/defense/fp/defense_result.pt
