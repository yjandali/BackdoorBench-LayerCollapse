2024-11-15:06:44:05 [INFO    ] [ft-sam.py:234] {'ExponentialLR_gamma': 0.9,
 'adaptive': True,
 'alpha': 0.0,
 'amp': True,
 'batch_size': 256,
 'checkpoint_load': None,
 'checkpoint_save': 'record/wanet_0_1_ViT/defense/ft-sam/checkpoint/',
 'client_optimizer': 'AdamW',
 'dataset': 'cifar10',
 'dataset_path': './data/cifar10',
 'device': 'cuda:1',
 'epochs': 20,
 'frequency_save': 100,
 'img_size': (32, 32, 3),
 'index': None,
 'input_channel': 3,
 'input_height': 32,
 'input_width': 32,
 'label_smoothing': 0.1,
 'log': 'record/wanet_0_1_ViT/defense/ft-sam/log/',
 'lr': 1e-05,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'vit_b_16',
 'non_blocking': True,
 'num_classes': 10,
 'num_workers': 4,
 'pin_memory': True,
 'prefetch': False,
 'print_freq': 1,
 'random_seed': 0,
 'ratio': 0.05,
 'result_file': 'wanet_0_1_ViT',
 'rho': 2.0,
 'rho_max': 2.0,
 'rho_min': 2.0,
 'save_path': 'record/wanet_0_1_ViT/defense/ft-sam/',
 'sgd_momentum': 0.99,
 'terminal_info': ['./defense/ft-sam.py',
                   '--result_file',
                   'wanet_0_1_ViT',
                   '--yaml_path',
                   './config-vit/defense/ft-sam/cifar10.yaml',
                   '--dataset',
                   'cifar10',
                   '--epochs',
                   '20',
                   '--ratio',
                   '0.05',
                   '--device',
                   'cuda:1'],
 'wd': 0.0005,
 'yaml_path': './config-vit/defense/ft-sam/cifar10.yaml'}
2024-11-15:06:44:07 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
2024-11-15:06:44:14 [INFO    ] [ft-sam.py:312] Train: [1][2/10]	                     loss 0.4156460762023926 (0.4156460762023926	                     Acc@1 0.97265625 (0.97265625
2024-11-15:06:44:17 [INFO    ] [ft-sam.py:312] Train: [1][3/10]	                     loss 0.39929473400115967 (0.4074704051017761	                     Acc@1 0.984375 (0.978515625
2024-11-15:06:44:21 [INFO    ] [ft-sam.py:312] Train: [1][4/10]	                     loss 0.38705354928970337 (0.4006647864977519	                     Acc@1 0.9921875 (0.9830729166666666
2024-11-15:06:44:25 [INFO    ] [ft-sam.py:312] Train: [1][5/10]	                     loss 0.39387115836143494 (0.39896637946367264	                     Acc@1 0.984375 (0.9833984375
2024-11-15:06:44:29 [INFO    ] [ft-sam.py:312] Train: [1][6/10]	                     loss 0.3797122836112976 (0.3951155602931976	                     Acc@1 1.0 (0.98671875
2024-11-15:06:44:32 [INFO    ] [ft-sam.py:312] Train: [1][7/10]	                     loss 0.3648354113101959 (0.3900688687960307	                     Acc@1 1.0 (0.9889322916666666
2024-11-15:06:44:36 [INFO    ] [ft-sam.py:312] Train: [1][8/10]	                     loss 0.3861318826675415 (0.38950644220624653	                     Acc@1 0.98828125 (0.9888392857142857
2024-11-15:06:44:40 [INFO    ] [ft-sam.py:312] Train: [1][9/10]	                     loss 0.37571069598197937 (0.3877819739282131	                     Acc@1 0.9921875 (0.9892578125
2024-11-15:06:44:44 [INFO    ] [ft-sam.py:312] Train: [1][10/10]	                     loss 0.36876729130744934 (0.3856692314147949	                     Acc@1 0.98046875 (0.98828125
2024-11-15:06:44:47 [INFO    ] [ft-sam.py:312] Train: [1][11/10]	                     loss 0.34815171360969543 (0.3827278580188751	                     Acc@1 0.9948979591836735 (0.9888
2024-11-15:06:45:59 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9394510024123721,
 'clean_test_loss_avg_over_batch': 0.1022190791554749,
 'test_acc': 0.9676,
 'test_asr': 0.32,
 'test_ra': 0.6576666666666666,
 'train_acc': 0.9888,
 'train_epoch_loss_avg_over_batch': 0.3827278580188751}
2024-11-15:06:46:03 [INFO    ] [ft-sam.py:312] Train: [2][2/10]	                     loss 0.33581680059432983 (0.33581680059432983	                     Acc@1 0.99609375 (0.99609375
2024-11-15:06:46:07 [INFO    ] [ft-sam.py:312] Train: [2][3/10]	                     loss 0.3325013816356659 (0.33415909111499786	                     Acc@1 0.9921875 (0.994140625
2024-11-15:06:46:11 [INFO    ] [ft-sam.py:312] Train: [2][4/10]	                     loss 0.33056575059890747 (0.3329613109429677	                     Acc@1 0.99609375 (0.9947916666666666
2024-11-15:06:46:14 [INFO    ] [ft-sam.py:312] Train: [2][5/10]	                     loss 0.31127017736434937 (0.32753852754831314	                     Acc@1 1.0 (0.99609375
2024-11-15:06:46:18 [INFO    ] [ft-sam.py:312] Train: [2][6/10]	                     loss 0.3323095738887787 (0.32849273681640623	                     Acc@1 0.984375 (0.99375
2024-11-15:06:46:22 [INFO    ] [ft-sam.py:312] Train: [2][7/10]	                     loss 0.3245145082473755 (0.3278296987215678	                     Acc@1 0.984375 (0.9921875
2024-11-15:06:46:26 [INFO    ] [ft-sam.py:312] Train: [2][8/10]	                     loss 0.28449270129203796 (0.3216386990887778	                     Acc@1 0.99609375 (0.9927455357142857
2024-11-15:06:46:30 [INFO    ] [ft-sam.py:312] Train: [2][9/10]	                     loss 0.27699145674705505 (0.31605779379606247	                     Acc@1 0.98828125 (0.9921875
2024-11-15:06:46:34 [INFO    ] [ft-sam.py:312] Train: [2][10/10]	                     loss 0.29133695363998413 (0.31331103377872044	                     Acc@1 0.984375 (0.9913194444444444
2024-11-15:06:46:37 [INFO    ] [ft-sam.py:312] Train: [2][11/10]	                     loss 0.2583093047142029 (0.30899889822006227	                     Acc@1 1.0 (0.992
2024-11-15:06:47:48 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.2000345057911344,
 'clean_test_loss_avg_over_batch': 0.11921287393197418,
 'test_acc': 0.9615,
 'test_asr': 0.24322222222222223,
 'test_ra': 0.7284444444444444,
 'train_acc': 0.992,
 'train_epoch_loss_avg_over_batch': 0.30899889822006227}
2024-11-15:06:47:52 [INFO    ] [ft-sam.py:312] Train: [3][2/10]	                     loss 0.2432425618171692 (0.2432425618171692	                     Acc@1 1.0 (1.0
2024-11-15:06:47:56 [INFO    ] [ft-sam.py:312] Train: [3][3/10]	                     loss 0.2598223090171814 (0.2515324354171753	                     Acc@1 0.98828125 (0.994140625
2024-11-15:06:48:00 [INFO    ] [ft-sam.py:312] Train: [3][4/10]	                     loss 0.23747088015079498 (0.24684525032838187	                     Acc@1 0.98828125 (0.9921875
2024-11-15:06:48:04 [INFO    ] [ft-sam.py:312] Train: [3][5/10]	                     loss 0.21281476318836212 (0.23833762854337692	                     Acc@1 1.0 (0.994140625
2024-11-15:06:48:08 [INFO    ] [ft-sam.py:312] Train: [3][6/10]	                     loss 0.22494661808013916 (0.23565942645072938	                     Acc@1 0.98828125 (0.99296875
2024-11-15:06:48:12 [INFO    ] [ft-sam.py:312] Train: [3][7/10]	                     loss 0.1990264654159546 (0.22955393294493356	                     Acc@1 0.99609375 (0.9934895833333334
2024-11-15:06:48:16 [INFO    ] [ft-sam.py:312] Train: [3][8/10]	                     loss 0.19896362721920013 (0.2251838892698288	                     Acc@1 0.9921875 (0.9933035714285714
2024-11-15:06:48:20 [INFO    ] [ft-sam.py:312] Train: [3][9/10]	                     loss 0.18435710668563843 (0.220080541446805	                     Acc@1 0.99609375 (0.99365234375
2024-11-15:06:48:24 [INFO    ] [ft-sam.py:312] Train: [3][10/10]	                     loss 0.18899482488632202 (0.21662657294008467	                     Acc@1 0.98046875 (0.9921875
2024-11-15:06:48:26 [INFO    ] [ft-sam.py:312] Train: [3][11/10]	                     loss 0.1804463118314743 (0.2137900404691696	                     Acc@1 0.9846938775510204 (0.9916
2024-11-15:06:49:38 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.8827857375144958,
 'clean_test_loss_avg_over_batch': 0.157388505525887,
 'test_acc': 0.9583,
 'test_asr': 0.28633333333333333,
 'test_ra': 0.6873333333333334,
 'train_acc': 0.9916,
 'train_epoch_loss_avg_over_batch': 0.2137900404691696}
2024-11-15:06:49:42 [INFO    ] [ft-sam.py:312] Train: [4][2/10]	                     loss 0.17180830240249634 (0.17180830240249634	                     Acc@1 0.98828125 (0.98828125
2024-11-15:06:49:46 [INFO    ] [ft-sam.py:312] Train: [4][3/10]	                     loss 0.16706685721874237 (0.16943757981061935	                     Acc@1 0.984375 (0.986328125
2024-11-15:06:49:49 [INFO    ] [ft-sam.py:312] Train: [4][4/10]	                     loss 0.15911883115768433 (0.16599799692630768	                     Acc@1 0.984375 (0.9856770833333334
2024-11-15:06:49:53 [INFO    ] [ft-sam.py:312] Train: [4][5/10]	                     loss 0.149086132645607 (0.1617700308561325	                     Acc@1 0.99609375 (0.98828125
2024-11-15:06:49:57 [INFO    ] [ft-sam.py:312] Train: [4][6/10]	                     loss 0.1638026088476181 (0.16217654645442964	                     Acc@1 0.984375 (0.9875
2024-11-15:06:50:01 [INFO    ] [ft-sam.py:312] Train: [4][7/10]	                     loss 0.146283358335495 (0.15952768176794052	                     Acc@1 0.99609375 (0.9889322916666666
2024-11-15:06:50:05 [INFO    ] [ft-sam.py:312] Train: [4][8/10]	                     loss 0.12316539883613586 (0.15433306992053986	                     Acc@1 0.99609375 (0.9899553571428571
2024-11-15:06:50:09 [INFO    ] [ft-sam.py:312] Train: [4][9/10]	                     loss 0.126174196600914 (0.15081321075558662	                     Acc@1 1.0 (0.9912109375
2024-11-15:06:50:13 [INFO    ] [ft-sam.py:312] Train: [4][10/10]	                     loss 0.1335642784833908 (0.14889666272534263	                     Acc@1 0.98828125 (0.9908854166666666
2024-11-15:06:50:16 [INFO    ] [ft-sam.py:312] Train: [4][11/10]	                     loss 0.12396534532308578 (0.1469420474410057	                     Acc@1 0.9948979591836735 (0.9912
2024-11-15:06:51:27 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.52739926510387,
 'clean_test_loss_avg_over_batch': 0.16779711293056607,
 'test_acc': 0.9623,
 'test_asr': 0.36044444444444446,
 'test_ra': 0.6226666666666667,
 'train_acc': 0.9912,
 'train_epoch_loss_avg_over_batch': 0.1469420474410057}
2024-11-15:06:51:31 [INFO    ] [ft-sam.py:312] Train: [5][2/10]	                     loss 0.13701599836349487 (0.13701599836349487	                     Acc@1 0.98828125 (0.98828125
2024-11-15:06:51:35 [INFO    ] [ft-sam.py:312] Train: [5][3/10]	                     loss 0.11730092018842697 (0.12715845927596092	                     Acc@1 1.0 (0.994140625
2024-11-15:06:51:38 [INFO    ] [ft-sam.py:312] Train: [5][4/10]	                     loss 0.12560126185417175 (0.12663939346869788	                     Acc@1 0.99609375 (0.9947916666666666
2024-11-15:06:51:42 [INFO    ] [ft-sam.py:312] Train: [5][5/10]	                     loss 0.1140994280576706 (0.12350440211594105	                     Acc@1 0.9921875 (0.994140625
2024-11-15:06:51:46 [INFO    ] [ft-sam.py:312] Train: [5][6/10]	                     loss 0.11906292289495468 (0.12261610627174377	                     Acc@1 0.99609375 (0.99453125
2024-11-15:06:51:50 [INFO    ] [ft-sam.py:312] Train: [5][7/10]	                     loss 0.11237864196300507 (0.12090986222028732	                     Acc@1 0.99609375 (0.9947916666666666
2024-11-15:06:51:54 [INFO    ] [ft-sam.py:312] Train: [5][8/10]	                     loss 0.1168556809425354 (0.12033069346632276	                     Acc@1 0.98828125 (0.9938616071428571
2024-11-15:06:51:58 [INFO    ] [ft-sam.py:312] Train: [5][9/10]	                     loss 0.11236205697059631 (0.11933461390435696	                     Acc@1 1.0 (0.99462890625
2024-11-15:06:52:02 [INFO    ] [ft-sam.py:312] Train: [5][10/10]	                     loss 0.11167018115520477 (0.11848301026556227	                     Acc@1 0.9921875 (0.9943576388888888
2024-11-15:06:52:05 [INFO    ] [ft-sam.py:312] Train: [5][11/10]	                     loss 0.11548729240894318 (0.11824814598560333	                     Acc@1 0.9897959183673469 (0.994
2024-11-15:06:53:16 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.7989152802361383,
 'clean_test_loss_avg_over_batch': 0.16855445224791765,
 'test_acc': 0.9653,
 'test_asr': 0.281,
 'test_ra': 0.7015555555555556,
 'train_acc': 0.994,
 'train_epoch_loss_avg_over_batch': 0.11824814598560333}
2024-11-15:06:53:20 [INFO    ] [ft-sam.py:312] Train: [6][2/10]	                     loss 0.11449924111366272 (0.11449924111366272	                     Acc@1 0.98828125 (0.98828125
2024-11-15:06:53:24 [INFO    ] [ft-sam.py:312] Train: [6][3/10]	                     loss 0.10583893954753876 (0.11016909033060074	                     Acc@1 1.0 (0.994140625
2024-11-15:06:53:28 [INFO    ] [ft-sam.py:312] Train: [6][4/10]	                     loss 0.11325688660144806 (0.11119835575421651	                     Acc@1 0.99609375 (0.9947916666666666
2024-11-15:06:53:31 [INFO    ] [ft-sam.py:312] Train: [6][5/10]	                     loss 0.10412243008613586 (0.10942937433719635	                     Acc@1 1.0 (0.99609375
2024-11-15:06:53:35 [INFO    ] [ft-sam.py:312] Train: [6][6/10]	                     loss 0.09767328202724457 (0.107078155875206	                     Acc@1 0.9921875 (0.9953125
2024-11-15:06:53:39 [INFO    ] [ft-sam.py:312] Train: [6][7/10]	                     loss 0.10875721275806427 (0.1073579986890157	                     Acc@1 0.9921875 (0.9947916666666666
2024-11-15:06:53:43 [INFO    ] [ft-sam.py:312] Train: [6][8/10]	                     loss 0.10805034637451172 (0.10745690550122942	                     Acc@1 0.9921875 (0.9944196428571429
2024-11-15:06:53:47 [INFO    ] [ft-sam.py:312] Train: [6][9/10]	                     loss 0.09726908057928085 (0.10618342738598585	                     Acc@1 0.99609375 (0.99462890625
2024-11-15:06:53:51 [INFO    ] [ft-sam.py:312] Train: [6][10/10]	                     loss 0.09283961355686188 (0.10470078140497208	                     Acc@1 1.0 (0.9952256944444444
2024-11-15:06:53:54 [INFO    ] [ft-sam.py:312] Train: [6][11/10]	                     loss 0.10312926024198532 (0.10457757414579391	                     Acc@1 1.0 (0.9956
2024-11-15:06:55:05 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9387602276272244,
 'clean_test_loss_avg_over_batch': 0.17501313164830207,
 'test_acc': 0.9663,
 'test_asr': 0.24333333333333335,
 'test_ra': 0.7372222222222222,
 'train_acc': 0.9956,
 'train_epoch_loss_avg_over_batch': 0.10457757414579391}
2024-11-15:06:55:09 [INFO    ] [ft-sam.py:312] Train: [7][2/10]	                     loss 0.09889867901802063 (0.09889867901802063	                     Acc@1 1.0 (1.0
2024-11-15:06:55:13 [INFO    ] [ft-sam.py:312] Train: [7][3/10]	                     loss 0.10787393152713776 (0.1033863052725792	                     Acc@1 0.99609375 (0.998046875
2024-11-15:06:55:17 [INFO    ] [ft-sam.py:312] Train: [7][4/10]	                     loss 0.09843233972787857 (0.10173498342434566	                     Acc@1 0.99609375 (0.9973958333333334
2024-11-15:06:55:21 [INFO    ] [ft-sam.py:312] Train: [7][5/10]	                     loss 0.09740989655256271 (0.10065371170639992	                     Acc@1 0.99609375 (0.9970703125
2024-11-15:06:55:24 [INFO    ] [ft-sam.py:312] Train: [7][6/10]	                     loss 0.09286396950483322 (0.09909576326608657	                     Acc@1 1.0 (0.99765625
2024-11-15:06:55:28 [INFO    ] [ft-sam.py:312] Train: [7][7/10]	                     loss 0.09455457329750061 (0.09833889827132225	                     Acc@1 0.99609375 (0.9973958333333334
2024-11-15:06:55:32 [INFO    ] [ft-sam.py:312] Train: [7][8/10]	                     loss 0.09369387477636337 (0.09767532348632812	                     Acc@1 1.0 (0.9977678571428571
2024-11-15:06:55:36 [INFO    ] [ft-sam.py:312] Train: [7][9/10]	                     loss 0.0888122171163559 (0.0965674351900816	                     Acc@1 1.0 (0.998046875
2024-11-15:06:55:40 [INFO    ] [ft-sam.py:312] Train: [7][10/10]	                     loss 0.08955137431621552 (0.09578787287076314	                     Acc@1 1.0 (0.9982638888888888
2024-11-15:06:55:43 [INFO    ] [ft-sam.py:312] Train: [7][11/10]	                     loss 0.08981816470623016 (0.09531984775066375	                     Acc@1 1.0 (0.9984
2024-11-15:06:56:54 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9655984971258376,
 'clean_test_loss_avg_over_batch': 0.1823720395565033,
 'test_acc': 0.9661,
 'test_asr': 0.23466666666666666,
 'test_ra': 0.7456666666666667,
 'train_acc': 0.9984,
 'train_epoch_loss_avg_over_batch': 0.09531984775066375}
2024-11-15:06:56:58 [INFO    ] [ft-sam.py:312] Train: [8][2/10]	                     loss 0.08275795727968216 (0.08275795727968216	                     Acc@1 1.0 (1.0
2024-11-15:06:57:02 [INFO    ] [ft-sam.py:312] Train: [8][3/10]	                     loss 0.09963919967412949 (0.09119857847690582	                     Acc@1 0.99609375 (0.998046875
2024-11-15:06:57:06 [INFO    ] [ft-sam.py:312] Train: [8][4/10]	                     loss 0.0888793095946312 (0.09042548884948094	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:06:57:10 [INFO    ] [ft-sam.py:312] Train: [8][5/10]	                     loss 0.09589352458715439 (0.09179249778389931	                     Acc@1 0.99609375 (0.998046875
2024-11-15:06:57:14 [INFO    ] [ft-sam.py:312] Train: [8][6/10]	                     loss 0.09374644607305527 (0.0921832874417305	                     Acc@1 0.9921875 (0.996875
2024-11-15:06:57:17 [INFO    ] [ft-sam.py:312] Train: [8][7/10]	                     loss 0.08393347263336182 (0.09080831830700238	                     Acc@1 1.0 (0.9973958333333334
2024-11-15:06:57:21 [INFO    ] [ft-sam.py:312] Train: [8][8/10]	                     loss 0.08602768182754517 (0.0901253702385085	                     Acc@1 0.99609375 (0.9972098214285714
2024-11-15:06:57:25 [INFO    ] [ft-sam.py:312] Train: [8][9/10]	                     loss 0.08548106998205185 (0.08954483270645142	                     Acc@1 1.0 (0.99755859375
2024-11-15:06:57:29 [INFO    ] [ft-sam.py:312] Train: [8][10/10]	                     loss 0.08735756576061249 (0.08930180304580265	                     Acc@1 1.0 (0.9978298611111112
2024-11-15:06:57:32 [INFO    ] [ft-sam.py:312] Train: [8][11/10]	                     loss 0.0871281698346138 (0.08913139020204544	                     Acc@1 1.0 (0.998
2024-11-15:06:58:43 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.979193949037128,
 'clean_test_loss_avg_over_batch': 0.18590689785778522,
 'test_acc': 0.9666,
 'test_asr': 0.23077777777777778,
 'test_ra': 0.7496666666666667,
 'train_acc': 0.998,
 'train_epoch_loss_avg_over_batch': 0.08913139020204544}
2024-11-15:06:58:47 [INFO    ] [ft-sam.py:312] Train: [9][2/10]	                     loss 0.08633700013160706 (0.08633700013160706	                     Acc@1 1.0 (1.0
2024-11-15:06:58:51 [INFO    ] [ft-sam.py:312] Train: [9][3/10]	                     loss 0.10133563727140427 (0.09383631870150566	                     Acc@1 0.9921875 (0.99609375
2024-11-15:06:58:55 [INFO    ] [ft-sam.py:312] Train: [9][4/10]	                     loss 0.08609715104103088 (0.09125659614801407	                     Acc@1 1.0 (0.9973958333333334
2024-11-15:06:58:59 [INFO    ] [ft-sam.py:312] Train: [9][5/10]	                     loss 0.09151562303304672 (0.09132135286927223	                     Acc@1 1.0 (0.998046875
2024-11-15:06:59:03 [INFO    ] [ft-sam.py:312] Train: [9][6/10]	                     loss 0.08207499980926514 (0.08947208225727081	                     Acc@1 1.0 (0.9984375
2024-11-15:06:59:06 [INFO    ] [ft-sam.py:312] Train: [9][7/10]	                     loss 0.08711306005716324 (0.08907891189058621	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:06:59:10 [INFO    ] [ft-sam.py:312] Train: [9][8/10]	                     loss 0.08805437386035919 (0.0889325493148395	                     Acc@1 1.0 (0.9988839285714286
2024-11-15:06:59:14 [INFO    ] [ft-sam.py:312] Train: [9][9/10]	                     loss 0.09132349491119385 (0.08923141751438379	                     Acc@1 0.9921875 (0.998046875
2024-11-15:06:59:18 [INFO    ] [ft-sam.py:312] Train: [9][10/10]	                     loss 0.0760452002286911 (0.08776628226041794	                     Acc@1 1.0 (0.9982638888888888
2024-11-15:06:59:21 [INFO    ] [ft-sam.py:312] Train: [9][11/10]	                     loss 0.07857876271009445 (0.08704598072767257	                     Acc@1 1.0 (0.9984
2024-11-15:07:00:32 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9852127267254724,
 'clean_test_loss_avg_over_batch': 0.1892535164952278,
 'test_acc': 0.9667,
 'test_asr': 0.23,
 'test_ra': 0.7507777777777778,
 'train_acc': 0.9984,
 'train_epoch_loss_avg_over_batch': 0.08704598072767257}
2024-11-15:07:00:36 [INFO    ] [ft-sam.py:312] Train: [10][2/10]	                     loss 0.08258172124624252 (0.08258172124624252	                     Acc@1 1.0 (1.0
2024-11-15:07:00:40 [INFO    ] [ft-sam.py:312] Train: [10][3/10]	                     loss 0.08959827572107315 (0.08608999848365784	                     Acc@1 1.0 (1.0
2024-11-15:07:00:44 [INFO    ] [ft-sam.py:312] Train: [10][4/10]	                     loss 0.08128945529460907 (0.08448981742064159	                     Acc@1 1.0 (1.0
2024-11-15:07:00:48 [INFO    ] [ft-sam.py:312] Train: [10][5/10]	                     loss 0.08538071811199188 (0.08471254259347916	                     Acc@1 1.0 (1.0
2024-11-15:07:00:52 [INFO    ] [ft-sam.py:312] Train: [10][6/10]	                     loss 0.09936544299125671 (0.08764312267303467	                     Acc@1 0.9921875 (0.9984375
2024-11-15:07:00:56 [INFO    ] [ft-sam.py:312] Train: [10][7/10]	                     loss 0.08156551420688629 (0.0866301879286766	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:00:59 [INFO    ] [ft-sam.py:312] Train: [10][8/10]	                     loss 0.0962236151099205 (0.08800067752599716	                     Acc@1 0.99609375 (0.9983258928571429
2024-11-15:07:01:03 [INFO    ] [ft-sam.py:312] Train: [10][9/10]	                     loss 0.07711297273635864 (0.08663971442729235	                     Acc@1 1.0 (0.99853515625
2024-11-15:07:01:07 [INFO    ] [ft-sam.py:312] Train: [10][10/10]	                     loss 0.08197461068630219 (0.08612136956718233	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:01:10 [INFO    ] [ft-sam.py:312] Train: [10][11/10]	                     loss 0.0925169438123703 (0.08662278258800507	                     Acc@1 1.0 (0.9988
2024-11-15:07:02:21 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9757870237032573,
 'clean_test_loss_avg_over_batch': 0.18424519542604684,
 'test_acc': 0.9668,
 'test_asr': 0.2301111111111111,
 'test_ra': 0.7506666666666667,
 'train_acc': 0.9988,
 'train_epoch_loss_avg_over_batch': 0.08662278258800507}
2024-11-15:07:02:25 [INFO    ] [ft-sam.py:312] Train: [11][2/10]	                     loss 0.08274327963590622 (0.08274327963590622	                     Acc@1 1.0 (1.0
2024-11-15:07:02:29 [INFO    ] [ft-sam.py:312] Train: [11][3/10]	                     loss 0.08032726496458054 (0.08153527230024338	                     Acc@1 1.0 (1.0
2024-11-15:07:02:33 [INFO    ] [ft-sam.py:312] Train: [11][4/10]	                     loss 0.08583439886569977 (0.08296831448872884	                     Acc@1 0.99609375 (0.9986979166666666
2024-11-15:07:02:37 [INFO    ] [ft-sam.py:312] Train: [11][5/10]	                     loss 0.10029421001672745 (0.08729978837072849	                     Acc@1 0.99609375 (0.998046875
2024-11-15:07:02:41 [INFO    ] [ft-sam.py:312] Train: [11][6/10]	                     loss 0.08971183001995087 (0.08778219670057297	                     Acc@1 1.0 (0.9984375
2024-11-15:07:02:44 [INFO    ] [ft-sam.py:312] Train: [11][7/10]	                     loss 0.08047010004520416 (0.08656351392467816	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:02:48 [INFO    ] [ft-sam.py:312] Train: [11][8/10]	                     loss 0.090408094227314 (0.08711273968219757	                     Acc@1 1.0 (0.9988839285714286
2024-11-15:07:02:52 [INFO    ] [ft-sam.py:312] Train: [11][9/10]	                     loss 0.09489604830741882 (0.08808565326035023	                     Acc@1 0.99609375 (0.99853515625
2024-11-15:07:02:56 [INFO    ] [ft-sam.py:312] Train: [11][10/10]	                     loss 0.0817011222243309 (0.08737626092301475	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:02:59 [INFO    ] [ft-sam.py:312] Train: [11][11/10]	                     loss 0.09179331362247467 (0.08772255785465241	                     Acc@1 1.0 (0.9988
2024-11-15:07:04:10 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9848879509501987,
 'clean_test_loss_avg_over_batch': 0.18611208274960517,
 'test_acc': 0.9668,
 'test_asr': 0.23022222222222222,
 'test_ra': 0.7504444444444445,
 'train_acc': 0.9988,
 'train_epoch_loss_avg_over_batch': 0.08772255785465241}
2024-11-15:07:04:14 [INFO    ] [ft-sam.py:312] Train: [12][2/10]	                     loss 0.08043348789215088 (0.08043348789215088	                     Acc@1 1.0 (1.0
2024-11-15:07:04:18 [INFO    ] [ft-sam.py:312] Train: [12][3/10]	                     loss 0.08884255588054657 (0.08463802188634872	                     Acc@1 1.0 (1.0
2024-11-15:07:04:22 [INFO    ] [ft-sam.py:312] Train: [12][4/10]	                     loss 0.08310549706220627 (0.08412718027830124	                     Acc@1 1.0 (1.0
2024-11-15:07:04:26 [INFO    ] [ft-sam.py:312] Train: [12][5/10]	                     loss 0.09298649430274963 (0.08634200878441334	                     Acc@1 1.0 (1.0
2024-11-15:07:04:30 [INFO    ] [ft-sam.py:312] Train: [12][6/10]	                     loss 0.08469587564468384 (0.08601278215646743	                     Acc@1 0.99609375 (0.99921875
2024-11-15:07:04:34 [INFO    ] [ft-sam.py:312] Train: [12][7/10]	                     loss 0.08344405144453049 (0.08558466037114461	                     Acc@1 1.0 (0.9993489583333334
2024-11-15:07:04:37 [INFO    ] [ft-sam.py:312] Train: [12][8/10]	                     loss 0.07677960395812988 (0.08432679516928536	                     Acc@1 1.0 (0.9994419642857143
2024-11-15:07:04:41 [INFO    ] [ft-sam.py:312] Train: [12][9/10]	                     loss 0.08557149767875671 (0.08448238298296928	                     Acc@1 1.0 (0.99951171875
2024-11-15:07:04:45 [INFO    ] [ft-sam.py:312] Train: [12][10/10]	                     loss 0.10487043857574463 (0.08674772249327765	                     Acc@1 0.98046875 (0.9973958333333334
2024-11-15:07:04:48 [INFO    ] [ft-sam.py:312] Train: [12][11/10]	                     loss 0.08474106341600418 (0.08659040042161942	                     Acc@1 1.0 (0.9976
2024-11-15:07:05:59 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9857853088113997,
 'clean_test_loss_avg_over_batch': 0.18387262523174286,
 'test_acc': 0.9668,
 'test_asr': 0.2298888888888889,
 'test_ra': 0.7507777777777778,
 'train_acc': 0.9976,
 'train_epoch_loss_avg_over_batch': 0.08659040042161942}
2024-11-15:07:06:03 [INFO    ] [ft-sam.py:312] Train: [13][2/10]	                     loss 0.08974909782409668 (0.08974909782409668	                     Acc@1 1.0 (1.0
2024-11-15:07:06:07 [INFO    ] [ft-sam.py:312] Train: [13][3/10]	                     loss 0.0875789076089859 (0.08866400271654129	                     Acc@1 1.0 (1.0
2024-11-15:07:06:11 [INFO    ] [ft-sam.py:312] Train: [13][4/10]	                     loss 0.07861930131912231 (0.08531576891740163	                     Acc@1 1.0 (1.0
2024-11-15:07:06:15 [INFO    ] [ft-sam.py:312] Train: [13][5/10]	                     loss 0.08001522719860077 (0.08399063348770142	                     Acc@1 1.0 (1.0
2024-11-15:07:06:19 [INFO    ] [ft-sam.py:312] Train: [13][6/10]	                     loss 0.09104043990373611 (0.08540059477090836	                     Acc@1 1.0 (1.0
2024-11-15:07:06:23 [INFO    ] [ft-sam.py:312] Train: [13][7/10]	                     loss 0.07734627276659012 (0.08405820777018864	                     Acc@1 1.0 (1.0
2024-11-15:07:06:26 [INFO    ] [ft-sam.py:312] Train: [13][8/10]	                     loss 0.08862706273794174 (0.08471090133701052	                     Acc@1 1.0 (1.0
2024-11-15:07:06:30 [INFO    ] [ft-sam.py:312] Train: [13][9/10]	                     loss 0.08340838551521301 (0.08454808685928583	                     Acc@1 0.99609375 (0.99951171875
2024-11-15:07:06:34 [INFO    ] [ft-sam.py:312] Train: [13][10/10]	                     loss 0.08190575242042542 (0.0842544941438569	                     Acc@1 1.0 (0.9995659722222222
2024-11-15:07:06:37 [INFO    ] [ft-sam.py:312] Train: [13][11/10]	                     loss 0.08826136589050293 (0.08456863288879395	                     Acc@1 1.0 (0.9996
2024-11-15:07:07:48 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9705740014712017,
 'clean_test_loss_avg_over_batch': 0.1831096563488245,
 'test_acc': 0.9671,
 'test_asr': 0.22922222222222222,
 'test_ra': 0.7518888888888889,
 'train_acc': 0.9996,
 'train_epoch_loss_avg_over_batch': 0.08456863288879395}
2024-11-15:07:07:52 [INFO    ] [ft-sam.py:312] Train: [14][2/10]	                     loss 0.08288843929767609 (0.08288843929767609	                     Acc@1 0.99609375 (0.99609375
2024-11-15:07:07:56 [INFO    ] [ft-sam.py:312] Train: [14][3/10]	                     loss 0.08269210159778595 (0.08279027044773102	                     Acc@1 1.0 (0.998046875
2024-11-15:07:08:00 [INFO    ] [ft-sam.py:312] Train: [14][4/10]	                     loss 0.08341798186302185 (0.0829995075861613	                     Acc@1 0.9921875 (0.99609375
2024-11-15:07:08:04 [INFO    ] [ft-sam.py:312] Train: [14][5/10]	                     loss 0.08560660481452942 (0.08365128189325333	                     Acc@1 0.99609375 (0.99609375
2024-11-15:07:08:08 [INFO    ] [ft-sam.py:312] Train: [14][6/10]	                     loss 0.08850124478340149 (0.08462127447128295	                     Acc@1 0.9921875 (0.9953125
2024-11-15:07:08:12 [INFO    ] [ft-sam.py:312] Train: [14][7/10]	                     loss 0.07438990473747253 (0.08291604618231456	                     Acc@1 1.0 (0.99609375
2024-11-15:07:08:16 [INFO    ] [ft-sam.py:312] Train: [14][8/10]	                     loss 0.09328952431678772 (0.08439797163009644	                     Acc@1 0.99609375 (0.99609375
2024-11-15:07:08:19 [INFO    ] [ft-sam.py:312] Train: [14][9/10]	                     loss 0.0778931975364685 (0.08358487486839294	                     Acc@1 0.99609375 (0.99609375
2024-11-15:07:08:23 [INFO    ] [ft-sam.py:312] Train: [14][10/10]	                     loss 0.08268186450004578 (0.08348454038302104	                     Acc@1 1.0 (0.9965277777777778
2024-11-15:07:08:26 [INFO    ] [ft-sam.py:312] Train: [14][11/10]	                     loss 0.08034630864858627 (0.08323850301504135	                     Acc@1 1.0 (0.9968
2024-11-15:07:09:37 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 1.9917965200212266,
 'clean_test_loss_avg_over_batch': 0.18659028112888337,
 'test_acc': 0.9673,
 'test_asr': 0.22466666666666665,
 'test_ra': 0.7558888888888889,
 'train_acc': 0.9968,
 'train_epoch_loss_avg_over_batch': 0.08323850301504135}
2024-11-15:07:09:41 [INFO    ] [ft-sam.py:312] Train: [15][2/10]	                     loss 0.07336993515491486 (0.07336993515491486	                     Acc@1 1.0 (1.0
2024-11-15:07:09:45 [INFO    ] [ft-sam.py:312] Train: [15][3/10]	                     loss 0.08563444763422012 (0.07950219139456749	                     Acc@1 0.99609375 (0.998046875
2024-11-15:07:09:49 [INFO    ] [ft-sam.py:312] Train: [15][4/10]	                     loss 0.08796848356723785 (0.08232428878545761	                     Acc@1 0.99609375 (0.9973958333333334
2024-11-15:07:09:53 [INFO    ] [ft-sam.py:312] Train: [15][5/10]	                     loss 0.07249447703361511 (0.07986683584749699	                     Acc@1 0.99609375 (0.9970703125
2024-11-15:07:09:57 [INFO    ] [ft-sam.py:312] Train: [15][6/10]	                     loss 0.08865368366241455 (0.0816242054104805	                     Acc@1 0.99609375 (0.996875
2024-11-15:07:10:01 [INFO    ] [ft-sam.py:312] Train: [15][7/10]	                     loss 0.07322808355093002 (0.08022485176722209	                     Acc@1 1.0 (0.9973958333333334
2024-11-15:07:10:05 [INFO    ] [ft-sam.py:312] Train: [15][8/10]	                     loss 0.06862227618694305 (0.07856734097003937	                     Acc@1 1.0 (0.9977678571428571
2024-11-15:07:10:09 [INFO    ] [ft-sam.py:312] Train: [15][9/10]	                     loss 0.07265433669090271 (0.07782821543514729	                     Acc@1 0.99609375 (0.99755859375
2024-11-15:07:10:12 [INFO    ] [ft-sam.py:312] Train: [15][10/10]	                     loss 0.08247239887714386 (0.07834423581759135	                     Acc@1 1.0 (0.9978298611111112
2024-11-15:07:10:15 [INFO    ] [ft-sam.py:312] Train: [15][11/10]	                     loss 0.06821959465742111 (0.077550463950634	                     Acc@1 1.0 (0.998
2024-11-15:07:11:26 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.0025915337933435,
 'clean_test_loss_avg_over_batch': 0.18820043317973614,
 'test_acc': 0.968,
 'test_asr': 0.21966666666666668,
 'test_ra': 0.7607777777777778,
 'train_acc': 0.998,
 'train_epoch_loss_avg_over_batch': 0.077550463950634}
2024-11-15:07:11:31 [INFO    ] [ft-sam.py:312] Train: [16][2/10]	                     loss 0.07347032427787781 (0.07347032427787781	                     Acc@1 0.99609375 (0.99609375
2024-11-15:07:11:34 [INFO    ] [ft-sam.py:312] Train: [16][3/10]	                     loss 0.07531562447547913 (0.07439297437667847	                     Acc@1 1.0 (0.998046875
2024-11-15:07:11:38 [INFO    ] [ft-sam.py:312] Train: [16][4/10]	                     loss 0.06926721334457397 (0.07268438736597697	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:11:42 [INFO    ] [ft-sam.py:312] Train: [16][5/10]	                     loss 0.07241980731487274 (0.07261824235320091	                     Acc@1 1.0 (0.9990234375
2024-11-15:07:11:46 [INFO    ] [ft-sam.py:312] Train: [16][6/10]	                     loss 0.06666994094848633 (0.071428582072258	                     Acc@1 1.0 (0.99921875
2024-11-15:07:11:50 [INFO    ] [ft-sam.py:312] Train: [16][7/10]	                     loss 0.06200955808162689 (0.06985874474048615	                     Acc@1 1.0 (0.9993489583333334
2024-11-15:07:11:54 [INFO    ] [ft-sam.py:312] Train: [16][8/10]	                     loss 0.06803172826766968 (0.06959774238722664	                     Acc@1 1.0 (0.9994419642857143
2024-11-15:07:11:58 [INFO    ] [ft-sam.py:312] Train: [16][9/10]	                     loss 0.07578754425048828 (0.07037146762013435	                     Acc@1 1.0 (0.99951171875
2024-11-15:07:12:01 [INFO    ] [ft-sam.py:312] Train: [16][10/10]	                     loss 0.07746066153049469 (0.07115915583239661	                     Acc@1 1.0 (0.9995659722222222
2024-11-15:07:12:04 [INFO    ] [ft-sam.py:312] Train: [16][11/10]	                     loss 0.0637870728969574 (0.07058118453025818	                     Acc@1 1.0 (0.9996
2024-11-15:07:13:15 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.0155769222312503,
 'clean_test_loss_avg_over_batch': 0.18699595853686332,
 'test_acc': 0.9691,
 'test_asr': 0.211,
 'test_ra': 0.7703333333333333,
 'train_acc': 0.9996,
 'train_epoch_loss_avg_over_batch': 0.07058118453025818}
2024-11-15:07:13:20 [INFO    ] [ft-sam.py:312] Train: [17][2/10]	                     loss 0.06768255680799484 (0.06768255680799484	                     Acc@1 1.0 (1.0
2024-11-15:07:13:23 [INFO    ] [ft-sam.py:312] Train: [17][3/10]	                     loss 0.06971724331378937 (0.0686999000608921	                     Acc@1 1.0 (1.0
2024-11-15:07:13:27 [INFO    ] [ft-sam.py:312] Train: [17][4/10]	                     loss 0.061142027378082275 (0.06618060916662216	                     Acc@1 1.0 (1.0
2024-11-15:07:13:31 [INFO    ] [ft-sam.py:312] Train: [17][5/10]	                     loss 0.06413397938013077 (0.06566895171999931	                     Acc@1 1.0 (1.0
2024-11-15:07:13:35 [INFO    ] [ft-sam.py:312] Train: [17][6/10]	                     loss 0.06666746735572815 (0.06586865484714508	                     Acc@1 1.0 (1.0
2024-11-15:07:13:39 [INFO    ] [ft-sam.py:312] Train: [17][7/10]	                     loss 0.0653047114610672 (0.06577466428279877	                     Acc@1 1.0 (1.0
2024-11-15:07:13:43 [INFO    ] [ft-sam.py:312] Train: [17][8/10]	                     loss 0.05770210176706314 (0.0646214410662651	                     Acc@1 1.0 (1.0
2024-11-15:07:13:47 [INFO    ] [ft-sam.py:312] Train: [17][9/10]	                     loss 0.064542256295681 (0.06461154296994209	                     Acc@1 1.0 (1.0
2024-11-15:07:13:50 [INFO    ] [ft-sam.py:312] Train: [17][10/10]	                     loss 0.055151209235191345 (0.06356039477719201	                     Acc@1 1.0 (1.0
2024-11-15:07:13:53 [INFO    ] [ft-sam.py:312] Train: [17][11/10]	                     loss 0.060520075261592865 (0.06332203372716903	                     Acc@1 1.0 (1.0
2024-11-15:07:15:05 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.0983124640252857,
 'clean_test_loss_avg_over_batch': 0.18757205829024315,
 'test_acc': 0.9697,
 'test_asr': 0.18833333333333332,
 'test_ra': 0.7923333333333333,
 'train_acc': 1.0,
 'train_epoch_loss_avg_over_batch': 0.06332203372716903}
2024-11-15:07:15:09 [INFO    ] [ft-sam.py:312] Train: [18][2/10]	                     loss 0.055804479867219925 (0.055804479867219925	                     Acc@1 0.99609375 (0.99609375
2024-11-15:07:15:13 [INFO    ] [ft-sam.py:312] Train: [18][3/10]	                     loss 0.05274639278650284 (0.05427543632686138	                     Acc@1 1.0 (0.998046875
2024-11-15:07:15:16 [INFO    ] [ft-sam.py:312] Train: [18][4/10]	                     loss 0.06275321543216705 (0.05710136269529661	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:15:20 [INFO    ] [ft-sam.py:312] Train: [18][5/10]	                     loss 0.06285085529088974 (0.05853873584419489	                     Acc@1 0.99609375 (0.998046875
2024-11-15:07:15:24 [INFO    ] [ft-sam.py:312] Train: [18][6/10]	                     loss 0.056154124438762665 (0.058061813563108446	                     Acc@1 1.0 (0.9984375
2024-11-15:07:15:28 [INFO    ] [ft-sam.py:312] Train: [18][7/10]	                     loss 0.056632108986377716 (0.057823529466986656	                     Acc@1 1.0 (0.9986979166666666
2024-11-15:07:15:32 [INFO    ] [ft-sam.py:312] Train: [18][8/10]	                     loss 0.05425967276096344 (0.05731440708041191	                     Acc@1 1.0 (0.9988839285714286
2024-11-15:07:15:36 [INFO    ] [ft-sam.py:312] Train: [18][9/10]	                     loss 0.056027017533779144 (0.057153483387082815	                     Acc@1 1.0 (0.9990234375
2024-11-15:07:15:40 [INFO    ] [ft-sam.py:312] Train: [18][10/10]	                     loss 0.061436496675014496 (0.05762937375240856	                     Acc@1 1.0 (0.9991319444444444
2024-11-15:07:15:43 [INFO    ] [ft-sam.py:312] Train: [18][11/10]	                     loss 0.052910856902599335 (0.057259442031383515	                     Acc@1 1.0 (0.9992
2024-11-15:07:16:54 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.13304211695989,
 'clean_test_loss_avg_over_batch': 0.17941326294094323,
 'test_acc': 0.9708,
 'test_asr': 0.18022222222222223,
 'test_ra': 0.8002222222222222,
 'train_acc': 0.9992,
 'train_epoch_loss_avg_over_batch': 0.057259442031383515}
2024-11-15:07:16:58 [INFO    ] [ft-sam.py:312] Train: [19][2/10]	                     loss 0.048059843480587006 (0.048059843480587006	                     Acc@1 1.0 (1.0
2024-11-15:07:17:02 [INFO    ] [ft-sam.py:312] Train: [19][3/10]	                     loss 0.05481104925274849 (0.05143544636666775	                     Acc@1 1.0 (1.0
2024-11-15:07:17:05 [INFO    ] [ft-sam.py:312] Train: [19][4/10]	                     loss 0.04970389977097511 (0.05085826416810354	                     Acc@1 1.0 (1.0
2024-11-15:07:17:09 [INFO    ] [ft-sam.py:312] Train: [19][5/10]	                     loss 0.051286712288856506 (0.05096537619829178	                     Acc@1 1.0 (1.0
2024-11-15:07:17:13 [INFO    ] [ft-sam.py:312] Train: [19][6/10]	                     loss 0.048775896430015564 (0.05052748024463653	                     Acc@1 1.0 (1.0
2024-11-15:07:17:17 [INFO    ] [ft-sam.py:312] Train: [19][7/10]	                     loss 0.04998712241649628 (0.05043742060661316	                     Acc@1 1.0 (1.0
2024-11-15:07:17:21 [INFO    ] [ft-sam.py:312] Train: [19][8/10]	                     loss 0.04927444830536842 (0.05027128170643534	                     Acc@1 1.0 (1.0
2024-11-15:07:17:25 [INFO    ] [ft-sam.py:312] Train: [19][9/10]	                     loss 0.0457424595952034 (0.04970517894253135	                     Acc@1 1.0 (1.0
2024-11-15:07:17:29 [INFO    ] [ft-sam.py:312] Train: [19][10/10]	                     loss 0.05007646605372429 (0.04974643306599723	                     Acc@1 1.0 (1.0
2024-11-15:07:17:32 [INFO    ] [ft-sam.py:312] Train: [19][11/10]	                     loss 0.04984068125486374 (0.049753822124004365	                     Acc@1 1.0 (1.0
2024-11-15:07:18:43 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.2059811684820385,
 'clean_test_loss_avg_over_batch': 0.18712623678147794,
 'test_acc': 0.9714,
 'test_asr': 0.15844444444444444,
 'test_ra': 0.8212222222222222,
 'train_acc': 1.0,
 'train_epoch_loss_avg_over_batch': 0.049753822124004365}
2024-11-15:07:18:47 [INFO    ] [ft-sam.py:312] Train: [20][2/10]	                     loss 0.04513770341873169 (0.04513770341873169	                     Acc@1 1.0 (1.0
2024-11-15:07:18:51 [INFO    ] [ft-sam.py:312] Train: [20][3/10]	                     loss 0.05102262645959854 (0.048080164939165115	                     Acc@1 1.0 (1.0
2024-11-15:07:18:55 [INFO    ] [ft-sam.py:312] Train: [20][4/10]	                     loss 0.04664815962314606 (0.04760282983382543	                     Acc@1 1.0 (1.0
2024-11-15:07:18:58 [INFO    ] [ft-sam.py:312] Train: [20][5/10]	                     loss 0.0442410409450531 (0.04676238261163235	                     Acc@1 1.0 (1.0
2024-11-15:07:19:02 [INFO    ] [ft-sam.py:312] Train: [20][6/10]	                     loss 0.04188869148492813 (0.0457876443862915	                     Acc@1 1.0 (1.0
2024-11-15:07:19:06 [INFO    ] [ft-sam.py:312] Train: [20][7/10]	                     loss 0.039252281188964844 (0.04469841718673706	                     Acc@1 1.0 (1.0
2024-11-15:07:19:10 [INFO    ] [ft-sam.py:312] Train: [20][8/10]	                     loss 0.03834442049264908 (0.04379070337329592	                     Acc@1 1.0 (1.0
2024-11-15:07:19:14 [INFO    ] [ft-sam.py:312] Train: [20][9/10]	                     loss 0.04490487277507782 (0.04392997454851866	                     Acc@1 1.0 (1.0
2024-11-15:07:19:18 [INFO    ] [ft-sam.py:312] Train: [20][10/10]	                     loss 0.04454055055975914 (0.043997816327545375	                     Acc@1 1.0 (1.0
2024-11-15:07:19:21 [INFO    ] [ft-sam.py:312] Train: [20][11/10]	                     loss 0.04420582950115204 (0.04401412456035614	                     Acc@1 1.0 (1.0
2024-11-15:07:20:32 [INFO    ] [trainer_cls.py:65] {'bd_test_loss_avg_over_batch': 2.2184024386935763,
 'clean_test_loss_avg_over_batch': 0.1839919650927186,
 'test_acc': 0.9714,
 'test_asr': 0.14833333333333334,
 'test_ra': 0.8317777777777777,
 'train_acc': 1.0,
 'train_epoch_loss_avg_over_batch': 0.04401412456035614}
2024-11-15:07:20:32 [INFO    ] [save_load_attack.py:176] saving...
